{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "# **Proyecto Final Aprendizaje Automático 2021-2022**\n",
        "---\n",
        "\n",
        "\n",
        "##**Alumno 1** : Francisco Pertíñez Perea\n",
        "##**Alumno 2** : Álvaro Santana Sánchez\n",
        "\n",
        "##**Grupo**: A2\n",
        "\n",
        "\n",
        "#**BBDD**: Cardiotocography\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14m680B612TzlB7QpsKPwDVVomn-dYUxU\">\n"
      ],
      "metadata": {
        "id": "Wy8ifZhkIbL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>***1. Definición del problema a resolver y enfoque elegido. Identifique el uso de los datos en el\n",
        "ajuste y valoración de resultados***</font>\n",
        "\n",
        "\n",
        "- Información extraída del repositorio UCI:\n",
        "http://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
        "\n",
        "\n",
        "- **Descripción del problema**: \n",
        "  - El conjunto de datos consta de una serie de mediciones sobre\n",
        "frecuencias cardiacas fetales y características de contracción uterina en un cardiograma. \n",
        "  - El objetivo es realizar una clasificación sobre el estado de los fetos a partir de dichas\n",
        "características. La clasificación dentro del dataset ha sido realizada por obstetras expertos.\n",
        "\n",
        "  - Se utilizará un enfoque de aprendizaje supervisado, ya que no existe un modelo establecido que ajustando los parámetros nos permita resolver el problema ( diseño ) y los elementos contienen etiquetas.\n",
        "\n",
        "\n",
        "- **Conjunto de datos $X$**: 2126 instancias con 23 atributos\n",
        "  - Información de los atributos:\n",
        "    - LB - latidos por minuto\n",
        "    - AC - aceleraciones por segundo\n",
        "    - FM - movimientos fetales por segundo\n",
        "    - UC - contracciones del útero por segundo\n",
        "    - DL - desaceleraciones suaves por segundo\n",
        "    - DS - deceleraciones fuertes por segundo -\n",
        "    - DP - deceleraciones prolongadas por segundo\n",
        "    - ASTV - porcentaje de tiempo con variabilidad anormal a corto plazo\n",
        "    - MST - valor medio de la variabilidad a corto plazo\n",
        "    - VALTV - porcentaje de tiempo con variabilidad anormal a largo plazo\n",
        "    - MLTV - valor medio de la variabilidad a largo plazo\n",
        "    - Width - ancho del histograma FHR\n",
        "    - Min - Mínimo del histograma FHR\n",
        "    - Max - Máximo del histograma FHR\n",
        "    - Nmax - picos del histograma\n",
        "    - Nzeros - ceros del histograma\n",
        "    - Mode - modo del histograma\n",
        "    - Mean -media del histograma\n",
        "    - Median - mediana del histograma\n",
        "    - Variance - varianza del histograma\n",
        "    - Tendency - tendencia del histograma\n",
        "    - CLASS - código del patrón de clase de FHR ( del 1 al 10 )\n",
        "NSP - código del estado del feto (N=normal; S=sospechoso; P=patológico).\n",
        "\n",
        "    - El resto de variables ( A , B , C... ) son patrones morfológicos con los que se realiza la\n",
        "primera clasificación.\n",
        "\n",
        "\n",
        "- **Conjunto de etiquetas $Y$**: Existen dos salidas posibles a la clasificación. \n",
        "  - La primera en un código de patrón de clase de FHR con 10 posibles valores. \n",
        "  - El segundo un código de estado que indica si un fetos se encuentra normal ( indicado con un 1 ), se tienen sospechas ( indicado con un 2 ) o contiene alguna patología ( indicado con un 3).   \n",
        "  \n",
        "  - Se debe escoger entre uno de los dos, luego **se trabajará con la clasificación NSP** debido a su facilidad de entendimiento.\n",
        "\n",
        "- **Función de etiquetado $f$**: Es la función que trataremos de predecir y no conocemos, la\n",
        "cual, dada un elemento determina si contiene alguna patología o puede ser sospechoso de\n",
        "ella\n",
        "\n",
        "------------------\n"
      ],
      "metadata": {
        "id": "Z6PIVhxTWI2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Cargar datos del drive\n",
        "\n",
        "#Leemos los datos con pandas\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datos/ProyectoFinal/CTG.csv',skip_blank_lines=True)\n",
        "data = data.drop(0,axis=0)\n",
        "#Eliminamos las columnas de datos no relevates\n",
        "data = data.drop('FileName', axis=1)\n",
        "data = data.drop('SegFile', axis=1)\n",
        "data = data.drop('Date', axis=1)\n",
        "data = data.drop('e', axis=1)\n",
        "data = data.drop('b', axis=1)\n",
        "data = data.drop('LBE', axis=1)\n",
        "data = data.drop('CLASS', axis=1)\n",
        "data = data.drop('DR', axis=1)\n",
        "data = data.drop('A', axis=1)\n",
        "data = data.drop('B', axis=1)\n",
        "data = data.drop('C', axis=1)\n",
        "data = data.drop('E', axis=1)\n",
        "data = data.drop('AD', axis=1)\n",
        "data = data.drop('DE', axis=1)\n",
        "data = data.drop('LD', axis=1)\n",
        "data = data.drop('FS', axis=1)\n",
        "data = data.drop('SUSP', axis=1)\n",
        "\n",
        "print('\\n\\033[1mConjunto de datos:\\033[0m', 'CTG.csv')\n",
        "print('\\033[1mEjemplos en el dataset: \\033[0m',data.shape[0])\n",
        "print('\\033[1mNúmero de características por ejemplo + etiqueta:\\033[0m',data.shape[1])\n",
        "print('\\n\\033[1mTipos de atributos utilizados:\\033[0m \\n',data.dtypes)\n",
        "\n",
        "\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "PiyZcsyCJWNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8626088-2b5f-4072-a180-63a4f9ea0690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "\u001b[1mConjunto de datos:\u001b[0m CTG.csv\n",
            "\u001b[1mEjemplos en el dataset: \u001b[0m 2126\n",
            "\u001b[1mNúmero de características por ejemplo + etiqueta:\u001b[0m 23\n",
            "\n",
            "\u001b[1mTipos de atributos utilizados:\u001b[0m \n",
            " LB          float64\n",
            "AC          float64\n",
            "FM          float64\n",
            "UC          float64\n",
            "ASTV        float64\n",
            "MSTV        float64\n",
            "ALTV        float64\n",
            "MLTV        float64\n",
            "DL          float64\n",
            "DS          float64\n",
            "DP          float64\n",
            "Width       float64\n",
            "Min         float64\n",
            "Max         float64\n",
            "Nmax        float64\n",
            "Nzeros      float64\n",
            "Mode        float64\n",
            "Mean        float64\n",
            "Median      float64\n",
            "Variance    float64\n",
            "Tendency    float64\n",
            "D           float64\n",
            "NSP         float64\n",
            "dtype: object\n",
            "         LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...    Max  \\\n",
            "1     120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...  126.0   \n",
            "2     132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...  198.0   \n",
            "3     133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...  198.0   \n",
            "4     134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  170.0   \n",
            "5     132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...  170.0   \n",
            "...     ...  ...  ...  ...   ...   ...   ...   ...  ...  ...  ...    ...   \n",
            "2122  140.0  0.0  0.0  6.0  79.0   0.2  25.0   7.2  0.0  0.0  ...  177.0   \n",
            "2123  140.0  1.0  0.0  9.0  78.0   0.4  22.0   7.1  0.0  0.0  ...  169.0   \n",
            "2124  140.0  1.0  0.0  7.0  79.0   0.4  20.0   6.1  0.0  0.0  ...  170.0   \n",
            "2125  140.0  1.0  0.0  9.0  78.0   0.4  27.0   7.0  0.0  0.0  ...  169.0   \n",
            "2126  142.0  1.0  1.0  5.0  74.0   0.4  36.0   5.0  0.0  0.0  ...  159.0   \n",
            "\n",
            "      Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency    D  NSP  \n",
            "1      2.0     0.0  120.0  137.0   121.0      73.0       1.0  0.0  2.0  \n",
            "2      6.0     1.0  141.0  136.0   140.0      12.0       0.0  0.0  1.0  \n",
            "3      5.0     1.0  141.0  135.0   138.0      13.0       0.0  0.0  1.0  \n",
            "4     11.0     0.0  137.0  134.0   137.0      13.0       1.0  0.0  1.0  \n",
            "5      9.0     0.0  137.0  136.0   138.0      11.0       1.0  0.0  1.0  \n",
            "...    ...     ...    ...    ...     ...       ...       ...  ...  ...  \n",
            "2122   4.0     0.0  153.0  150.0   152.0       2.0       0.0  0.0  2.0  \n",
            "2123   6.0     0.0  152.0  148.0   151.0       3.0       1.0  0.0  2.0  \n",
            "2124   5.0     0.0  153.0  148.0   152.0       4.0       1.0  0.0  2.0  \n",
            "2125   6.0     0.0  152.0  147.0   151.0       4.0       1.0  0.0  2.0  \n",
            "2126   2.0     1.0  145.0  143.0   145.0       1.0       0.0  0.0  1.0  \n",
            "\n",
            "[2126 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Creación de los datos de entrenamiento**:\n",
        "Antes de realizar el análisis de los datos se debe de realizar una partición en training-test, la cuál será posteriormente utilizada para la estimación del error fuera de la muestra. Al\n",
        "realizar previamente la división evitaremos el data-snooping el cuál podrá dar lugar a\n",
        "modelos sesgados hacia nuestros datos y el problema no habrá sido abordado de manera\n",
        "acertada. \n",
        "\n",
        "- Para la división tomaremos un 80% de los datos para training ( 1700 elementos )\n",
        "y un 20% ( 426 elementos ) para test, los cuales son valores típicos. \n",
        "\n",
        "- El problema del conjunto de datos es que el número de ejemplos puede ser considerado bajo ( en torno a los 2000 ), pero debemos de establecer un compromiso entre usar menos datos para\n",
        "entrenar y por tanto pagar la penalización en el modelo ajustado, o usar menos datos en el\n",
        "conjunto de test y obtener una medición de error que sea menos representativa de aquello\n",
        "que pasará fuera de la muestra . \n",
        "\n",
        "- Utilizando dichos valores, nuestro error de test generaliza según la siguiente cota, teniendo en cuenta que como se usa una sola hipótesis $|H| = 1$:\n",
        "  - <font color=blue>$$E_{out}(h) \\leq E_{test}(h) + \\sqrt{\\frac{1}{2N}log \\frac{2|H|}{\\delta}} $$</font>\n",
        "    - Para una confianza del 96% ( $\\delta = 0.04 $ ):\n",
        "  - <font color=blue>$$E_{out}(h) \\leq E_{test}(h) + 0.04465 $$</font>\n",
        "\n",
        "\n",
        "**Función usada para la división:** usaremos la siguiente funcion que nos proporciona sklearn:\n",
        "\n",
        "sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None,\n",
        "random_state=None, shuffle=True, stratify=None)\n",
        "\n",
        "- **Descripción de parámetros**:\n",
        "  - *arrays : sequence of indexables with same length / shape[0]\n",
        "Referido al conjunto de elementos y etiquetas.\n",
        "  - test_size: float or int, default=None\n",
        "Tamaño del test a usar. Permite números enteros o flotantes, estando esto últimos entre 0 y 1. Por tanto indicaremos que use el 20% de los datos para test con 0.2 .\n",
        "  - training_size: float or int, default=None\n",
        "Misma idea, para indicarle el 80% de los datos podemos usar un flotante 0.8. Con indicar\n",
        "uno de los dos parámetros es suficiente.\n",
        "  - random_state: int, RandomState instance or None, default=None\n",
        "Permite controlar la mezcla aleatoria realizada antes de la partición de los datos. Siempre\n",
        "que el entero pasado no cambie, en todas nuestras ejecuciones la mezcla será la misma.\n",
        "  - shuffle: bool, default=True\n",
        "Indica si dicha mezcla aleatoria se producirá o no. Usaremos el valor true ya que siempre es\n",
        "buena idea mezclar nuestros datos aleatoriamente, además en muchos ficheros suelen\n",
        "venir ordenados utilizando algún criterio, lo cuál trataremos de evitar.\n",
        "  - stratify: array-like, default=None\n",
        "Indica si los datos se dividirán de una manera estratificada en el conjunto indicado ( en\n",
        "nuestro caso las clases ). Esto significa que si la distribución de etiquetas no está\n",
        "compensada, es decir, existen muchos más ejemplos de una clase que de otra entonces se\n",
        "distribuirán de forma que en un cross-validation de k-folds, los k-folds contengan una\n",
        "proporción similar de ambas clases"
      ],
      "metadata": {
        "id": "VlvSctL7Je9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#Separamos en un conjunto X de datos y un conjunto Y de etiquetas (columna y)\n",
        "dataX = data.drop('NSP', axis=1)\n",
        "dataY = data['NSP']\n",
        "\n",
        "#Relizamos la separación en conjuntos de test y training\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size = 0.2, random_state = 45,stratify=dataY)\n",
        "print('\\033[1mPrimeros elementos del conjunto de entrenamiento:\\033[0m ')\n",
        "print(dataX.head())\n",
        "print('\\n\\033[1mEtiquetas asociadas:\\033[0m ')\n",
        "print(dataY.head())\n",
        "print('\\n\\033[1mTamaño final entrenamiento:\\033[0m ', X_train.shape[0])\n",
        "print('\\033[1mTamaño final test:\\033[0m ', X_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8oI9g1JJhVj",
        "outputId": "01b8cdec-80b2-4aac-9037-1395e42be816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mPrimeros elementos del conjunto de entrenamiento:\u001b[0m \n",
            "      LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...   Min    Max  \\\n",
            "1  120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...  62.0  126.0   \n",
            "2  132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...  68.0  198.0   \n",
            "3  133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...  68.0  198.0   \n",
            "4  134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  53.0  170.0   \n",
            "5  132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...  53.0  170.0   \n",
            "\n",
            "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency    D  \n",
            "1   2.0     0.0  120.0  137.0   121.0      73.0       1.0  0.0  \n",
            "2   6.0     1.0  141.0  136.0   140.0      12.0       0.0  0.0  \n",
            "3   5.0     1.0  141.0  135.0   138.0      13.0       0.0  0.0  \n",
            "4  11.0     0.0  137.0  134.0   137.0      13.0       1.0  0.0  \n",
            "5   9.0     0.0  137.0  136.0   138.0      11.0       1.0  0.0  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "\n",
            "\u001b[1mEtiquetas asociadas:\u001b[0m \n",
            "1    2.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "5    1.0\n",
            "Name: NSP, dtype: float64\n",
            "\n",
            "\u001b[1mTamaño final entrenamiento:\u001b[0m  1700\n",
            "\u001b[1mTamaño final test:\u001b[0m  426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DESEQUILIBRIO DE CLASES**\n",
        "\n",
        "En primera instancia vamos a medir la distribución de clases. Encontramos que en un 77.82% los ejemplos son referentes a la clase 1 ( fetos normales ), en un 13.88% fetos sospechosos y un 8.24% fetos que presentan patologías. Dicha distribución de etiquetas era esperada debido a la naturaleza del problema ( comúnmente la mayoría de fetos se desarrollan de una manera normal ), pero nos obliga a trabajar con desequilibrio lo cuál puede tener implicaciones en el modelo las cuales se irán comentando a lo largo del proyecto."
      ],
      "metadata": {
        "id": "6TTUdNLXJ3la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Medimos el porcentaje de etiquetas de cada tipo\n",
        "etiquetasCount = y_train.value_counts()\n",
        "print(\"\\033[1m FIG 1.1 FRECUENCIA DE LAS ETIQUETAS:\\033[0m \")\n",
        "print(\"\\033[1m CLASE 1:\\033[0m \",etiquetasCount[1.0] , '->',100*etiquetasCount[1.0]/y_train.shape[0],'%')\n",
        "print(\"\\033[1m CLASE 2:\\033[0m \",etiquetasCount[2.0], '->',100*etiquetasCount[2.0]/y_train.shape[0],'%')\n",
        "print(\"\\033[1m CLASE 3:\\033[0m \",etiquetasCount[3.0], '->',100*etiquetasCount[3.0]/y_train.shape[0],'%')\n",
        "etiquetasCount.plot(kind = \"bar\",color='green')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.xlabel('Etiqueta')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title(\"Distribución de clases\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Z9WAjmtCJrse",
        "outputId": "8025b389-1301-4f8f-f597-d97f123e119d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m FIG 1.1 FRECUENCIA DE LAS ETIQUETAS:\u001b[0m \n",
            "\u001b[1m CLASE 1:\u001b[0m  1323 -> 77.82352941176471 %\n",
            "\u001b[1m CLASE 2:\u001b[0m  236 -> 13.882352941176471 %\n",
            "\u001b[1m CLASE 3:\u001b[0m  141 -> 8.294117647058824 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribución de clases')"
            ]
          },
          "metadata": {},
          "execution_count": 293
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEcCAYAAAA2g5hwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAatUlEQVR4nO3dfZRddX3v8feHBBAq8mB6WTFBgzXVSy1GGoFe+0ClVqFovGotthW0sdHUZ3S1aO1Fa721Vmv12lDSgoK1INLWpC5aRcRrvVbkoREVS4kIkpQHkWcRafB7/zi/KcdxJvtkmDnnDPN+rTUre//2Pvv3nTNrnU9+v7332akqJEnamd1GXYAkafwZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhcZOkr9I8vuzdKxHJ7k7yaK2/pkkL52NY0/q5+4kj53UtluSTUnWzmI/H0zyh7N1vHbMtyT569k8ph56Fo+6AC0sSa4FDgR2APcDVwJnARur6vsAVfXyXTjWS6vqU9PtU1XfBB7+4KruVlVT9fGHwIVVdfpc9y/NNcNCo/CsqvpUkn2BnwfeCxwBvGQ2O0myuKp2zOYxd0VVvWlUfUuzzWkojUxV3VFVm4FfBU5M8kT4wamWJEuSfDzJ7UluTfLPbXrnQ8CjgX9oU0C/k2RFkkqyNsk3gU/3tfX/x+jHknwxyZ1tmuiA1tdRSbb115jk2iS/2JYXJXlTkq8nuSvJZUkOatsqyePa8r5JzkryrSTXJXlzkt3athcn+VySdyW5Lck3khwz3XuU5MlJLm/9fQR42KTtxyXZ0t6fzyc5dCfH+okkF7T38aYkU4ZZko8muTHJHUk+m+Qn+rYdm+TKVs/2JG8YpJYkv9v2vyvJVUmOnq5OjSfDQiNXVV8EtgE/O8Xm17dtP0pv+upNvZfUi4Bv0hulPLyq3tn3mp8H/jvwjGm6PAH4TWApvemw9w1Y6knAC4FjgUe0Y9wzxX7/B9gXeGyr5QR+cNR0BHAVsAR4J3B6kkw+SJI9gI8BHwIOAD4KPK9v+5OBM4CXAY8ETgM2J9lzimPtA3wK+CfgUcDjgAun+T3/EVgJ/DfgcuDDfdtOB15WVfsATwQ+3VVLkscDrwSe0l73DODaafrWmDIsNC7+g94H4mT/Se9D/TFV9Z9V9c/V/YVmb6mq71TVd6fZ/qGq+kpVfQf4feAFEyfAO7wUeHNVXVU9X6qqb/fv0I5zPPDGqrqrqq4F3g28qG+366rqL6vqfuDM9vsdOEV/RwK7A3/WfvfzgEv6tq8DTquqi6vq/qo6E/hee91kxwE3VtW7q+reVtvFU/2SVXVG2/494C3Ak9qUIfT+HockeURV3VZVlw9Qy/3Anu11u1fVtVX19an61vgyLDQulgG3TtH+J8BW4JNJrkly8gDHun4Xtl9H7wN5yQDHPQjo+pBb0o533aQ+lvWt3zixUFUTI5OpTpA/Ctg+KRz7j/sY4PVt2uf2JLe3Gh81w9onptre0aba7uSBEcDE+/M8eiOr65L83yQ/3VVLVW0FXksveG5Ock6SqWrUGDMsNHJJnkLvw/Rzk7e1/+G+vqoeCzwbOKlvvnu6EUbXyOOgvuVH0/vf8i3Ad4C9++paRG/6a8L1wI91HPuWdrzHTOpje8frpnIDsGzSFNWjJ9Xz9qrar+9n76o6e4pjXU9vWqzLrwFrgF+kN5W2orUHoKouqao19KaoPgacO0gtVfU3VfUz9N6XAv54gFo0RgwLjUySRyQ5DjgH+Ouq+vIU+xyX5HHtA/MOelMa32+bb2KwD8DJfiPJIUn2Bv4AOK9NCf078LAkv5xkd+DN9KZPJvwV8LYkK9NzaJJH9h+4Hedc4O1J9knyGHrnOmZyH8O/0Dun8uokuyd5LnB43/a/BF6e5IhWz4+02veZ4lgfB5YmeW07j7BPkiOm2G8fetNH36YXnP97YkOSPZL8epJ9q+o/gTt54G8xbS1JHp/kae1cyr3Ad/tep3nCsNAo/EOSu+j9b/T3gD9l+stmV9I7MXs3vQ/PDVV1Udv2R8Cb27THG6Z5/VQ+BHyQ3nTQw4BXQ+/qLOC36YXCdnojjf6ro/6UXhB8kt4H5enAXlMc/1XttdfQGy39Db2Tv7ukqu4Dngu8mN4U3a8Cf9e3/VLgt4D3A7fRm6578TTHugt4OvAser/31cAvTLHrWfSmurbTuwfmC5O2vwi4tk1RvRz49QFq2RN4B71R1430RiVv7H4HNE7iw48kSV0cWUiSOhkWkqROhoUkqZNhIUnq9JD8IsElS5bUihUrRl2GJM0rl1122S1V9aNTbXtIhsWKFSu49NJLR12GJM0rSa6bbpvTUJKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROD8k7uIctb033TvNYneIzT6SFzpGFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6zVlYJDkjyc1JvtLX9idJ/i3JFUn+Psl+fdvemGRrkquSPKOv/ZmtbWuSk+eqXknS9OZyZPFB4JmT2i4AnlhVhwL/DrwRIMkhwPHAT7TXbEiyKMki4M+BY4BDgBe2fSVJQzRnYVFVnwVundT2yara0Va/ACxvy2uAc6rqe1X1DWArcHj72VpV11TVfcA5bV9J0hCN8rGqvwl8pC0voxceE7a1NoDrJ7UfMdXBkqwD1gEsXbqULVu2zGqxO7N++fqh9TUKw3wvJY2nkYRFkt8DdgAfnq1jVtVGYCPA6tWra9WqVbN16E6nbjp1aH2Nwoa1G0ZdgqQRG3pYJHkxcBxwdFVVa94OHNS32/LWxk7aJUlDMtRLZ5M8E/gd4NlVdU/fps3A8Un2THIwsBL4InAJsDLJwUn2oHcSfPMwa5YkzeHIIsnZwFHAkiTbgFPoXf20J3BBEoAvVNXLq+qrSc4FrqQ3PfWKqrq/HeeVwCeARcAZVfXVuapZkjS1OQuLqnrhFM2n72T/twNvn6L9fOD8WSxNkrSLvINbktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1mrOwSHJGkpuTfKWv7YAkFyS5uv27f2tPkvcl2ZrkiiSH9b3mxLb/1UlOnKt6JUnTm8uRxQeBZ05qOxm4sKpWAhe2dYBjgJXtZx1wKvTCBTgFOAI4HDhlImAkScMzZ2FRVZ8Fbp3UvAY4sy2fCTynr/2s6vkCsF+SpcAzgAuq6taqug24gB8OIEnSHFs85P4OrKob2vKNwIFteRlwfd9+21rbdO0/JMk6eqMSli5dypYtW2ax7J1bv3z90PoahWG+l5LG07DD4r9UVSWpWTzeRmAjwOrVq2vVqlWzdehOp246dWh9jcKGtRtGXYKkERv21VA3tekl2r83t/btwEF9+y1vbdO1S5KGaNhhsRmYuKLpRGBTX/sJ7aqoI4E72nTVJ4BfSrJ/O7H9S61NkjREczYNleRs4ChgSZJt9K5qegdwbpK1wHXAC9ru5wPHAluBe4CXAFTVrUneBlzS9vuDqpp80lySNMfmLCyq6oXTbDp6in0LeMU0xzkDOGMWS5Mk7SLv4JYkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKngcIiyZFJLklyd5L7ktyf5M65Lk6SNB4GHVm8H3ghcDWwF/BS4M/nqihJ0ngZeBqqqrYCi6rq/qr6APDMuStLkjROBg2Le5LsAWxJ8s4kr9uF1/6QJK9L8tUkX0lydpKHJTk4ycVJtib5SOuPJHu29a1t+4qZ9itJmplBP/BfBCwCXgl8BzgIeN5MOkyyDHg1sLqqntiOezzwx8B7qupxwG3A2vaStcBtrf09bT9J0hANFBZVdV1Vfbeq7qyqt1bVSW1aaqYWA3slWQzsDdwAPA04r20/E3hOW17T1mnbj06SB9G3JGkXLd7ZxiTnVtULknwZqMnbq+rQXe2wqrYneRfwTeC7wCeBy4Dbq2pH220bsKwtLwOub6/dkeQO4JHALbvatyRpZnYaFsBr2r/HzVaHSfanN1o4GLgd+CizcLI8yTpgHcDSpUvZsmXLgz3kwNYvXz+0vkZhmO+lpPG007Coqhva4m7ADVV1L0CSvYADZ9jnLwLfqKpvtWP9HfBUYL8ki9voYjmwve2/nd45km1t2mpf4NtT1LoR2AiwevXqWrVq1QzL23Wnbjp1aH2Nwoa1G0ZdgqQRG/QE90eB7/et39/aZuKbwJFJ9m7nHo4GrgQuAp7f9jkR2NSWN7d12vZPV9UPTYlJkubOoGGxuKrum1hpy3vMpMOqupjeierLgS+3GjYCvwuclGQrvXMSp7eXnA48srWfBJw8k34lSTPXdc5iwreSPLuqNgMkWcODOMFcVacAp0xqvgY4fIp97wV+ZaZ9SZIevEHD4uXAh5O8Hwi9q5NOmLOqJEljZaCwqKqv0zvP8PC2fvecViVJGisDhUWSPendsb0CWDxxT1xV/cGcVSZJGhuDTkNtAu6gd/Pc9+auHEnSOBo0LJZXld8yK0kL1KCXzn4+yU/OaSWSpLE16MjiZ4AXJ/kGvWmoADWT74aSJM0/g4bFMXNahSRprA38FeX0vp/paW35nkFfK0ma/wb6wE9yCr2v43hja9od+Ou5KkqSNF4GHR38T+DZ9J6SR1X9B7DPXBUlSRovg4bFfe2bXgsgyY/MXUmSpHEzaFicm+Q0es+c+C3gU8Bfzl1ZkqRxMuh3Q70rydOBO4HHA/+rqi6Y08okSWNj0EtnaeFgQEjSAjToFwneRTtfQe+hR7sD36mqR8xVYZKk8THoNNR/XfnUHoW6BjhyroqSJI2XXb6xrno+BjxjDuqRJI2hQaehntu3uhuwGrh3TiqSJI2dQU9wP6tveQdwLb2pKEnSAjDoOYuXzHUhkqTxNeh3Q52ZZL++9f2TnDF3ZUmSxsmgJ7gPrarbJ1aq6jbgyXNTkiRp3AwaFrsl2X9iJckB7MINfZMl2S/JeUn+LcnXkvx0kgOSXJDk6vbv/m3fJHlfkq1Jrkhy2Ez7lSTNzKBh8W7gX5K8LcnbgM8D73wQ/b4X+KeqegLwJOBrwMnAhVW1EriwrUPvwUsr28864NQH0a8kaQYGffjRWcBzgZvaz3Or6kMz6TDJvsDPAae3Y9/XprjWAGe23c4EntOW1wBntfs7vkDvywyXzqRvSdLM7MpU0gH0vuLjA0l+NMnBVfWNGfR5MPAt4ANJngRcBrwGOLCqbmj73Agc2JaXAdf3vX5ba7uhr40k6+iNPFi6dClbtmyZQWkzs375+qH1NQrDfC8ljadBb8o7hd6NeI8HPsADT8p76gz7PAx4VVVdnOS9PDDlBPTuEk9SU756GlW1EdgIsHr16lq1atUMSpuZUzc9tGfGNqzdMOoSJI3YKJ6Utw3YVlUXt/Xz6IXHTRPTS+3fm9v27fSe/z1heWuTJA3J0J+UV1U3AtcneXxrOhq4EtgMnNjaTgQ2teXNwAntqqgjgTv6pqskSUMw6DmLyU/K+00e3JPyXgV8OMkewDXAS+gF17lJ1gLXAS9o+54PHAtsBe5p+0qShqgzLNpXkn8EeAKz9KS8qtpC7xzIZEdPsW8Br5hpX5KkB68zLNrJ5vOr6ifxSXmStCANes7i8iRPmdNKJElja9BzFkcAv5HkWnpXRIXeoOPQuSpMkjQ+dhoWSR5dVd/Ep+JJ0oLWNbL4GHBYVV2X5G+r6nnDKEqSNF66zlmkb/mxc1mIJGl8dYVFTbMsSVpAuqahnpTkTnojjL3aMjxwgvsRc1qdJGks7DQsqmrRsAqRJI2vQe+zkCQtYIaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTiMLiySLkvxrko+39YOTXJxka5KPJNmjte/Z1re27StGVbMkLVSjHFm8Bvha3/ofA++pqscBtwFrW/ta4LbW/p62nyRpiEYSFkmWA78M/FVbD/A04Ly2y5nAc9rymrZO235021+SNCRdT8qbK38G/A6wT1t/JHB7Ve1o69uAZW15GXA9QFXtSHJH2/+W/gMmWQesA1i6dClbtmyZ01+g3/rl64fW1ygM872UNJ6GHhZJjgNurqrLkhw1W8etqo3ARoDVq1fXqlWrZuvQnU7ddOrQ+hqFDWs3jLoESSM2ipHFU4FnJzkWeBjwCOC9wH5JFrfRxXJge9t/O3AQsC3JYmBf4NvDL1uSFq6hn7OoqjdW1fKqWgEcD3y6qn4duAh4ftvtRGBTW97c1mnbP11VNcSSJWnBG6f7LH4XOCnJVnrnJE5v7acDj2ztJwEnj6g+SVqwRnWCG4Cq+gzwmbZ8DXD4FPvcC/zKUAuTJP2AcRpZSJLGlGEhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTotHXYA0anlrRl3CnKpTatQl6CHAkYUkqdPQwyLJQUkuSnJlkq8meU1rPyDJBUmubv/u39qT5H1Jtia5Islhw65Zkha6UYwsdgCvr6pDgCOBVyQ5BDgZuLCqVgIXtnWAY4CV7WcdcOrwS5akhW3oYVFVN1TV5W35LuBrwDJgDXBm2+1M4DlteQ1wVvV8AdgvydIhly1JC9pIz1kkWQE8GbgYOLCqbmibbgQObMvLgOv7XrattUmShmRkV0MleTjwt8Brq+rO5IErUqqqkuzSJRxJ1tGbpmLp0qVs2bJlNsvdqfXL1w+tr1EY5ns5Cv79pG6pGv5ldUl2Bz4OfKKq/rS1XQUcVVU3tGmmz1TV45Oc1pbPnrzfdMdfvXp1XXrppXP/izReejm/+feTepJcVlWrp9o2iquhApwOfG0iKJrNwIlt+URgU1/7Ce2qqCOBO3YWFJKk2TeKaainAi8CvpxkYnz8JuAdwLlJ1gLXAS9o284HjgW2AvcALxluuZKkoYdFVX0OmG7cf/QU+xfwijktSpK0U97BLUnqZFhIkjoZFpKkToaFJKmTX1EuaV57KN8nM073yDiykCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmd5k1YJHlmkquSbE1y8qjrkaSFZF6ERZJFwJ8DxwCHAC9Mcshoq5KkhWNehAVwOLC1qq6pqvuAc4A1I65JkhaMxaMuYEDLgOv71rcBR/TvkGQdsK6t3p3kqiHVNgpLgFuG1VnekmF1tVD495u/Hup/u8dMt2G+hEWnqtoIbBx1HcOQ5NKqWj3qOjQz/v3mr4X8t5sv01DbgYP61pe3NknSEMyXsLgEWJnk4CR7AMcDm0dckyQtGPNiGqqqdiR5JfAJYBFwRlV9dcRljdKCmG57CPPvN38t2L9dqmrUNUiSxtx8mYaSJI2QYSFJ6mRYSJI6GRaS1CHJAUkOGHUdo2RYSEOQ5MAkh7WfA0ddj7oleXSSc5J8C7gY+GKSm1vbitFWN3xeDTVPtA+YZW11e1XdNMp6NJgkq4C/APblgRtJlwO3A79dVZePqjbtXJJ/Af4MOK+q7m9ti4BfAV5bVUeOsr5hMyzGnB8281uSLcDLquriSe1HAqdV1ZNGU5m6JLm6qlbu6raHKsNizPlhM791fOBsrarHDbsmDSbJOcCtwJk88EWmBwEnAkuq6gWjqm0UDIsx54fN/JbkfcCPAWfxgx84JwDfqKpXjqo27Vz7aqG19B6HMDEFvA34B+D0qvreqGobBcNizPlhM/8lOYYf/MDZDmyuqvNHV5W0awyLecAPG2m8JDmuqj4+6jqGybCQRiTJuvYcFs0zSd5aVaeMuo5h8j6Leaw9HVDzl4+wG3NJDk/ylLZ8SJKTkhy70IIC5slXlGtaftjMA0meQG8K8eKqurtv03UjKkkDSHIKcAywOMkF9B7lfBFwcpInV9XbR1rgkDkNNY8leUlVfWDUdWh6SV4NvAL4GrAKeE1VbWrbLq+qw0ZZn6aX5Mv0/mZ7AjcCy6vqziR70Qv+Q0da4JA5spjf3goYFuPtt4Cfqqq721dEnJdkRVW9F0eG425Hu3P7niRfr6o7Aarqu0m+P+Lahs6wGHNJrphuE+B3DI2/3Samnqrq2iRH0QuMx2BYjLv7kuxdVfcAPzXRmGRfwLDQ2DkQeAZw26T2AJ8ffjnaRTclWVVVWwDaCOM44AzgJ0dbmjr83MSNd1XVHw6707uLe0ExLMbfx4GHT3zY9EvymeGXo110ArCjv6GqdgAnJDltNCVpENPdoV1VtwC3DLmckfMEtySpk/dZSJI6GRaSpE6GhdQhyf1JtvT9nNzaX5tk7779zk+y3yz3vSLJr83mMaWZ8JyF1CHJ3VX18CnarwVWtxOec9X3UcAbquq4uepDGoQjC2kG2p3ZjwIuSnJRa7s2yZK2/HtJ/j3J55KcneQNrf0zSVa35SUtcEiyKMmfJLkkyRVJXta6egfws21E87o20vjnJJe3n/8x5F9dC5SXzkrd9mpPLJzwR1X1viQnAb8weWSR5KeA4+l9VcRi4HLgso4+1gJ3VNVTkuwJ/L8knwROpm9k0aa9nl5V9yZZCZwNrJ6F31HaKcNC6vbdqlq1C/v/LPD37c5fkmwe4DW/BBya5PltfV9gJXDfpP12B97fns1+P/Dju1CXNGOGhTRcO3hg+vdhfe0BXlVVn+jfuZ2z6Pc64CbgSe04985NmdIP8pyFNHN3AftM0f5Z4DlJ9kqyD/Csvm3X8sD3DD2/r/0TwPokuwMk+fEkPzJFH/sCN7Svn3gRsGg2fhGpi2Ehddtr0qWz72jtG4F/mjjBPaGqLgc+AnwJ+Efgkr7N76IXCv8KLOlr/yvgSuDyJF8BTqM38r8CuD/Jl5K8DtgAnJjkS8ATgO/M9i8rTcVLZ6U5luQtwN1V9a5R1yLNlCMLSVInRxaSpE6OLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ3+P7RPBSoKOnLRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**ESTUDIO DE CORRELACIÓN ENTRE VARIABLES**:\n",
        " \n",
        "Podemos realizar una matriz de correlación entre atributos, sin embargo su representación será difícil de interpretar debido a la alta cantidad de atributos. Por tanto lo que haremos será calcular dicha matriz siguiendo como criterio el coeficiente de correlación de Pearson y a partir de dicho coeficiente calcular el porcentaje de valores relaciones según los siguientes criterios:\n",
        " \n",
        "- correlación total = 1 o -1: la relación es perfecta ya tenga pendiente positiva ( cuando una aumenta la otra también ) o negativa ( cuando una aumenta la otra disminuye )\n",
        " \n",
        "- correlación nula = 0 : no existe ninguna relación\n",
        " \n",
        "- correlación $\\in$ (-0.5,0.5): asociación débil\n",
        " \n",
        "- correlación $\\in$ (0.5,0.8) $\\cup$ (-0.8,-0.5): asociación moderada\n",
        " \n",
        "- correlación $\\in$ (0.8,1)  $\\cup$ (-1,-0.8) : asociación fuerte\n",
        " \n",
        "**Resultados:** Se aprecia que la mayoría de columnas tienen una asociación débil. Solo una pequeña cantidad de características cuenta con cierta relación moderada y otra pequeña cantidad de relaciones fuertes, las cuáles si pueden ser problemáticas a la hora del ajuste de nuestro modelo. Se observa también un porcentaje de atributos con relación total, los cuales podrían ser candidatos a unificarse, pero dicho porcentaje proviene de las correlaciones de cada atributo consigo mismo. Concluimos por tanto que cada columna contiene información propia que puede ser usada por el modelo para el aprendizaje, a expensas de algunos atributos cuyo coeficiente de pearson es superior a 0.8.\n",
        " \n",
        "Referencia: https://likegeeks.com/python-correlation-matrix/"
      ],
      "metadata": {
        "id": "eBim8j54Lt6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "#Calculamos la matriz de correlacion\n",
        "correlation_mat = X_train.corr()\n",
        "valores = ['nula','debil','moderada','fuerte','total']\n",
        "altura = []\n",
        "\n",
        "#Calculamos el porcentaje de cada clase\n",
        "altura.append(100*len(np.where((correlation_mat == 0.0 ))[0])/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat < 0.5) & (correlation_mat > 0.0)) |  ((correlation_mat > -0.5) & (correlation_mat < 0.0)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat >= 0.5) & (correlation_mat < 0.8)) |  ((correlation_mat <= -0.5) & (correlation_mat >= -0.8)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat >= 0.8) & (correlation_mat < 1)) |  ((correlation_mat <= -0.8) & (correlation_mat >= -1)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where((correlation_mat == 1 ) | (correlation_mat == -1))[0])/(X_train.shape[1]*X_train.shape[1])))"
      ],
      "metadata": {
        "id": "xD2Tq5wPLbQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1mFIG 1.2: Porcentajes de correlación entre variables según el coeficiente pearson\\033[0m')\n",
        "print('El porcentaje de atributos con relación total es debido a atributos consigo mismos')\n",
        "print('\\033[1mPorcentaje de correlaciones totales : \\033[0m',altura[4])\n",
        "print('\\033[1mPorcentaje de correlaciones de atributos medidas consigo mismo :\\033[0m',100*(1/X_train.shape[1]))\n",
        "print('\\n')\n",
        "plt.title('FIG 1.2: Porcentajes de correlación entre variables según el coeficiente pearson')\n",
        "plt.xlabel('Tipo de corelación')\n",
        "plt.ylabel('Porcentaje de atributos')\n",
        "plt.bar(valores,altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "jkSqXu0hLfgR",
        "outputId": "8386cd7a-ddd5-474b-8e3f-071452221fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mFIG 1.2: Porcentajes de correlación entre variables según el coeficiente pearson\u001b[0m\n",
            "El porcentaje de atributos con relación total es debido a atributos consigo mismos\n",
            "\u001b[1mPorcentaje de correlaciones totales : \u001b[0m 4.545454545454546\n",
            "\u001b[1mPorcentaje de correlaciones de atributos medidas consigo mismo :\u001b[0m 4.545454545454546\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 295
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESTUDIO DE LAS VARIABLES CONTINUAS**\n",
        "\n",
        "Realizaremos un análisis de las variables continuas donde mediremos valores de media, máximo, mínimo , varianza y desviación típica. Podemos destacar de la figura 1.3 como algunas de las variables cuentan con una varianza muy pequeña. Esto puede implicar que contengan poca información a la hora del aprendizaje y podrían ser candidatos a eliminarse. Por otro lado se observa que existen diferentes rangos dentro de los atributos del problema. Por un lado FM recoge valores desde 557 a 0, siendo el valor con un máximo mayor, frente a por ejemplo DP cuyos valores de cero a cuatro. Esto pone de manifiesto la necesidad de una futura normalización de los datos, cuyas ventajas serán comentadas posteriormente.\n"
      ],
      "metadata": {
        "id": "TOHFxZixNYrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "#Guardamos cuales son los atributos continuos\n",
        "atributosContinuos = np.where(X_train.dtypes != 'object')\n",
        "\n",
        "nombreAtributoCont = []\n",
        "media = []\n",
        "Sx = []\n",
        "maximo = []\n",
        "minimo = []\n",
        "var = []\n",
        "\n",
        "#Calculamos los valores de cada columnas\n",
        "for i in atributosContinuos[0]:\n",
        "  nombreAtributoCont.append(X_train.columns[i])\n",
        "  media.append(X_train[X_train.columns[i]].mean())\n",
        "  maximo.append(X_train[X_train.columns[i]].max())\n",
        "  minimo.append(X_train[X_train.columns[i]].min())\n",
        "  var.append(X_train[X_train.columns[i]].var())\n",
        "  Sx.append(X_train[X_train.columns[i]].std())\n",
        "\n",
        "\n",
        "#________________________TABLA SOBRE VARIABLES CONTINUAS________________________\n",
        "info = {'\\033[1mAtributo\\033[0m': nombreAtributoCont[:], \n",
        "        '\\033[1mMedia\\033[0m': media[:],\n",
        "        '\\033[1mMáximo\\033[0m': maximo[:],\n",
        "        '\\033[1mMínimo\\033[0m': minimo[:],\n",
        "        '\\033[1mVarianza\\033[0m': var[:],\n",
        "        '\\033[1mDesviación estándar\\033[0m': Sx[:]}\n",
        "print(\"\\033[1m\"+'\\nFIG 1.3 % TABLA VALORES DE LOS ATRIBUTOS CONTINUOS\"'+\"\\033[0m\")\n",
        "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAuqLD4VNUqJ",
        "outputId": "9f2f72b5-e55c-46b8-fed5-4e8954d33e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "FIG 1.3 % TABLA VALORES DE LOS ATRIBUTOS CONTINUOS\"\u001b[0m\n",
            "╒════════════╤══════════════╤══════════╤══════════╤═══════════════╤═══════════════════════╕\n",
            "│ \u001b[1mAtributo\u001b[0m   │        \u001b[1mMedia\u001b[0m │   \u001b[1mMáximo\u001b[0m │   \u001b[1mMínimo\u001b[0m │      \u001b[1mVarianza\u001b[0m │   \u001b[1mDesviación estándar\u001b[0m │\n",
            "╞════════════╪══════════════╪══════════╪══════════╪═══════════════╪═══════════════════════╡\n",
            "│ LB         │ 133.162      │    160   │    106   │   97.1108     │             9.85448   │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ AC         │   2.73647    │     26   │      0   │   12.6827     │             3.56128   │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ FM         │   7.30647    │    557   │      0   │ 1370.6        │            37.0216    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ UC         │   3.64       │     23   │      0   │    8.04572    │             2.8365    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ ASTV       │  46.7876     │     86   │     12   │  296          │            17.2047    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ MSTV       │   1.34653    │      7   │      0.2 │    0.830965   │             0.911573  │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ ALTV       │   9.78765    │     91   │      0   │  336.803      │            18.3522    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ MLTV       │   8.28665    │     50.7 │      0   │   32.5977     │             5.70944   │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ DL         │   1.57529    │     16   │      0   │    6.29156    │             2.5083    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ DS         │   0.00352941 │      1   │      0   │    0.00351903 │             0.0593214 │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ DP         │   0.121765   │      4   │      0   │    0.208237   │             0.45633   │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Width      │  70.8076     │    180   │      3   │ 1545.11       │            39.3079    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Min        │  93.3635     │    159   │     50   │  884.925      │            29.7477    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Max        │ 164.171      │    238   │    122   │  329.569      │            18.154     │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Nmax       │   4.05588    │     18   │      0   │    8.56015    │             2.92577   │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Nzeros     │   0.325294   │     10   │      0   │    0.502126   │             0.708609  │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Mode       │ 137.175      │    186   │     60   │  274.467      │            16.5671    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Mean       │ 134.481      │    182   │     73   │  243.945      │            15.6187    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Median     │ 137.939      │    186   │     78   │  209.995      │            14.4912    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Variance   │  19.0012     │    269   │      0   │  869.416      │            29.4859    │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ Tendency   │   0.309412   │      1   │     -1   │    0.37625    │             0.613393  │\n",
            "├────────────┼──────────────┼──────────┼──────────┼───────────────┼───────────────────────┤\n",
            "│ D          │   0.0382353  │      1   │      0   │    0.036795   │             0.19182   │\n",
            "╘════════════╧══════════════╧══════════╧══════════╧═══════════════╧═══════════════════════╛\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>***2. Codificación de los datos de entrada para hacerlos útiles a los algoritmos.***</font>\n",
        "\n",
        "Debido a que todas las características con las que vamos a trabajar están en formato numérico (con el que ya puede trabajar el algoritmo) no haremos ninguna clase de codificación. Lo que sí haremos es una normalización de los datos, la cuál se explicará en su apartado correspondiente."
      ],
      "metadata": {
        "id": "zV_HQs8hWW-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>**3. Valoración del interés de la variables medidas para el problema y selección de un subconjunto\n",
        "(en su caso).**\n",
        "\n",
        "Tal y como hemos explicado en el apartado 1, únicamente usaremos las características que son útiles para la clasificación que hemos elegido (NSP) de las dos opciones que teníamos, por tanto **eliminaremos todas las variables que no sean útiles en nuestro estudio**, estas son las referentes a los patrones morfológicos con los que se hace la otra clasificación. También encontramos variables con una correlación fuerte, las cuales pueden unificarse debido a que el comportamiento de una explica el de la otra y por tanto mantener ambas puede tener efectos negativos en nuestros modelo. Por último, hemos encontrado variables cuya varianza es muy baja y esto puede ser indicativo de que contienen poca información para el aprendizaje de nuestro modelo. Aún así no eliminaremos dichas variables debido a que en sus pequeñas variaciones pueden contener información esencial para las distinguir entre las clases más desbalanceadas. Para poder seleccionar un mejor conjunto de variables usaremos PCA, para lo cual previamente deben ser normalizados los datos."
      ],
      "metadata": {
        "id": "kRpb50EWWZ5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>**4. Necesidad de la normalización de los datos e interés de la técnica usada (en su caso)**</font>\n",
        "\n",
        "**Normalización de variables:** nos permitirá formar funciones de coste más uniformes, donde es más sencillo encontrar mínimos en un menor número de pasos. Para ello usaremos tanto la media de los datos de training como su varianza. También normalizamos los datos de test con dichos valores, si tomamos medidas también sobre este conjunto crearemos sesgo en nuestro modelo el cuál afectará a la medida de error out sample. \n",
        "\n",
        "- La normalización que usaremos será el standart escalable, el cual consiste en:\n",
        " \n",
        "  - **Zero out mean:** Movemos el conjunto de elementos hasta que la media de estos sea cero.\n",
        " \n",
        "      <font color=blue>$$\\mu = \\frac{1}{m} \\sum^{m}_{i=1}{x^i}$$\n",
        "              \n",
        "      $$x = x - \\mu$$</font>\n",
        " \n",
        "  - **Normalize variance:** igualamos las varianzas de las variables siendo estas igual a uno.\n",
        "  <font color=blue>$$\\sigma ^2 = \\frac{1}{m} \\sum^{m}_{i=1}{(x^i)^2}$$\n",
        "\n",
        "      $$ x = \\frac{x}{\\sigma ^2}$$</font>\n",
        " \n",
        "\n",
        "- Su **implementación** en scikit learn:\n",
        " \n",
        "  *class sklearn.preprocessing.StandardScaler(, copy=True, with_mean=True, with_std=True)\n",
        "\n",
        "- **Descripción parámetros**:\n",
        " \n",
        "  - copy : bool, default=True - realiza una copia sobre los datos\n",
        " \n",
        "  - with_mean : bool, default=True - Mueve la media de los datos a cero.\n",
        " \n",
        "  - with_std : bool, default=True - Unifica la varianza.\n",
        " \n",
        "---\n",
        " \n",
        "Referencia: https://www.youtube.com/watch?v=FDCfw-YqWTE"
      ],
      "metadata": {
        "id": "C-SK97PNWj_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Escalado estándar de variables\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_scaled_train = scaler.transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_scaled_train, index=X_train.index, columns=X_train.columns)\n",
        "X_test = pd.DataFrame(X_scaled_test, index=X_test.index, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "OcUnaXoLRRT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Volvemos a medir los valores\n",
        "media = []\n",
        "Sx = []\n",
        "maximo = []\n",
        "minimo = []\n",
        "var = []\n",
        "indice = []\n",
        "\n",
        "for i in nombreAtributoCont:\n",
        "  media.append(X_train[i].mean())\n",
        "  maximo.append(X_train[i].max())\n",
        "  minimo.append(X_train[i].min())\n",
        "  var.append(X_train[i].var())\n",
        "  Sx.append(X_train[i].std())\n",
        "\n",
        "\n",
        "#________________________TABLA SOBRE VARIABLES CONTINUAS________________________\n",
        "info = {'\\033[1mAtributo\\033[0m': nombreAtributoCont[:], \n",
        "        '\\033[1mMedia\\033[0m': media[:],\n",
        "        '\\033[1mMáximo\\033[0m': maximo[:],\n",
        "        '\\033[1mMínimo\\033[0m': minimo[:],\n",
        "        '\\033[1mVarianza\\033[0m': var[:],\n",
        "        '\\033[1mDesviación estándar\\033[0m': Sx[:]}\n",
        "print(\"\\033[1m\"+'\\nTabla 4.1 VALORES DE LOS ATRIBUTOS NORMALIZADOS'+\"\\033[0m\")\n",
        "print(\"Se observa como la media vale cero y la varianza 1\")\n",
        "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))\n",
        "print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7IJq-qpRV_z",
        "outputId": "5e7a52fd-5207-4a48-ca15-8c98c220dfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "Tabla 4.1 VALORES DE LOS ATRIBUTOS NORMALIZADOS\u001b[0m\n",
            "Se observa como la media vale cero y la varianza 1\n",
            "╒════════════╤══════════════╤══════════╤═══════════╤════════════╤═══════════════════════╕\n",
            "│ \u001b[1mAtributo\u001b[0m   │        \u001b[1mMedia\u001b[0m │   \u001b[1mMáximo\u001b[0m │    \u001b[1mMínimo\u001b[0m │   \u001b[1mVarianza\u001b[0m │   \u001b[1mDesviación estándar\u001b[0m │\n",
            "╞════════════╪══════════════╪══════════╪═══════════╪════════════╪═══════════════════════╡\n",
            "│ LB         │  5.58507e-16 │  2.7242  │ -2.75716  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ AC         │  2.82127e-17 │  6.53427 │ -0.768621 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ FM         │  1.2539e-17  │ 14.8523  │ -0.197415 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ UC         │ -8.35933e-17 │  6.82733 │ -1.28365  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ ASTV       │ -7.10543e-17 │  2.27984 │ -2.02259  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ MSTV       │ -3.443e-16   │  6.20371 │ -1.25812  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ ALTV       │  3.55271e-17 │  4.42651 │ -0.53348  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ MLTV       │ -4.17966e-18 │  7.43083 │ -1.45182  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ DL         │  6.06051e-17 │  5.75249 │ -0.628218 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ DS         │  8.35933e-18 │ 16.8028  │ -0.059514 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ DP         │ -8.98628e-17 │  8.50125 │ -0.266913 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Width      │ -1.15986e-16 │  2.77869 │ -1.72554  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Min        │  1.2748e-16  │  2.20709 │ -1.45814  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Max        │  7.54429e-16 │  4.068   │ -2.32365  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Nmax       │  7.94136e-17 │  4.76736 │ -1.38667  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Nzeros     │ -2.82127e-17 │ 13.6571  │ -0.459195 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Mode       │ -6.67179e-16 │  2.94796 │ -4.65973  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Mean       │  7.04273e-16 │  3.04332 │ -3.93753  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Median     │  8.30708e-17 │  3.31755 │ -4.13744  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Variance   │  3.34373e-17 │  8.48109 │ -0.644606 │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ Tendency   │  2.08983e-17 │  1.12618 │ -2.13533  │    1.00059 │               1.00029 │\n",
            "├────────────┼──────────────┼──────────┼───────────┼────────────┼───────────────────────┤\n",
            "│ D          │  1.46288e-17 │  5.01536 │ -0.199387 │    1.00059 │               1.00029 │\n",
            "╘════════════╧══════════════╧══════════╧═══════════╧════════════╧═══════════════════════╛\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Reducción de variables PCA ( Principal Component Analysis)**:\n",
        "PCA es una técnica utilizada para la reducción de variables especialmente útil cuando existe múltiple colinealidad entre variables ( como en nuestro caso ), las dimensiones de entrada son demasiado grandes, o para realizar compresión en los datos y reducir el ruido.\n",
        "El análisis realizado por PCA es el siguiente:\n",
        "- Los datos de entrada deben son z-scored, de tal forma que cada variable tiene media cero y desviación estándar unitaria ( paso anterior ).\n",
        "- Se realiza la construcción y descomposición de valores propios de la matriz de covarianzas ( al ser la desviación estándar de todas las características 1, la covarianza es igual a la matriz de correlación )\n",
        "- Los valores propios se ordenan en orden decreciente respecto la varianza en los datos\n",
        "- Finalmente se realiza una proyección de los datos en el espacio reducido de PCA obtenido al multiplicar ( dot product ) los datos originales normalizados por los valores propios líderes de la matriz de covarianza.\n",
        "- El espacio nuevo de PCA maximiza la varianza original de los datos.\n",
        "La idea principal por tanto de PCA es la creación de los \"componentes principales\", los cuales son nuevas variables construidas como combinaciones lineales o mezclas de las variables principales. Estas combinaciones están hechas de manera que las nuevas variables están incorrelacionadas y la mayoría de información de las variables iniciales se comprime en estos componentes.\n",
        "\n",
        "**¿Cual es el número máximo de componente relevantes?**\n",
        "\n",
        "Debido al rango de la matriz de covarianzas, podemos obtener con PCA una cota superior de valores significativos. La matriz de covarianzas tendrá la forma nºelementos x nºcaracterísticas, luego el máximo rango será el mínimo entre ambas. Por ende podemos tener como mucho dicho valor de componentes significativas ( esto es poco relevante en nuestro problema, ya que acota el número de componentes significativas al número de variables del problema ).\n",
        "¿Cómo elegimos entonces el número de componentes?\n",
        "No es necesario elegir un número de componentes para la nueva matriz de datos de manera manual, indicamos al modelo que debe mantener una varianza explicada por los componentes generados del 99%, de esta manera nos aseguramos que el modelo siga manteniendo toda la información.\n",
        " \n",
        "---\n",
        " \n",
        "Implementación de PCA:\n",
        " \n",
        "**class sklearn.decomposition.PCA**(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', n_oversamples=10, power_iteration_normalizer='auto', random_state=None)\n",
        " \n",
        "- n_components: int, float or ‘mle’, default=None\n",
        " \n",
        "Al usar un flotante indicamos la cantidad de varianza explicada por los datos a mantener. Con un valor alto como 99% nuestro modelo conserva la información.\n",
        " \n",
        "- copy: bool, default=True\n",
        " \n",
        "No sobreescribe los datos.\n",
        " \n",
        "- whiten : bool, default=False\n",
        " \n",
        "Asegura outputs incorrelados con varianza en las anchuras de los componente unitarias. Puede perder información luego se queda en false.\n",
        " \n",
        "- svd_solver: {‘auto’, ‘full’, ‘arpack’, ‘randomized’}, default=’auto’\n",
        " \n",
        "El valor auto selecciona el mejor solucionador dependiendo de X.shape y el número de componentes.\n",
        " \n",
        "- tol : float, default=0.0\n",
        " \n",
        "Tolerancia a valores singulares. Solo interesante si solver ='arpack'\n",
        " \n",
        "- iterated_power: int or ‘auto’, default=’auto’\n",
        " \n",
        "Iteraciones en el método usado por el solver = 'randomized'\n",
        " \n",
        "- n_oversamples: int, default=10\n",
        " \n",
        "Número adicional de vectores aleatorio usado por el solver = 'randomized'\n",
        " \n",
        "- power_iteration_normalizer: {‘auto’, ‘QR’, ‘LU’, ‘none’}, default=’auto’\n",
        " \n",
        "Normalizador del poder de cada iteración\n",
        " \n",
        "- random_state: int, RandomState instance or None, default=None\n",
        " \n",
        "Semilla en los casos de 'arpack' y 'randomized'\n",
        " \n",
        "---\n",
        "Referencia 1: https://towardsdatascience.com/pca-clearly-explained-how-when-why-to-use-it-and-feature-importance-a-guide-in-python-7c274582c37e\n",
        "\n",
        "Referencia 2: https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/\n",
        " \n",
        " \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iKmXX2fnSGXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print('\\033[1mNúmero de características antes de la transformación: \\033[0m')\n",
        "print(X_train.shape[1])\n",
        "\n",
        "pca = PCA(n_components = 0.99)\n",
        "pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "print('\\033[1mNúmero de características después de la transformación: \\033[0m')\n",
        "print(X_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qObDdx07RmOW",
        "outputId": "b8355898-8dd9-40e3-fa3a-55151675a421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mNúmero de características antes de la transformación: \u001b[0m\n",
            "22\n",
            "\u001b[1mNúmero de características después de la transformación: \u001b[0m\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfica adaptada del enlace\n",
        "\n",
        "print('\\033[1m FIG 4.2:  Eleccion de componentes de PCA \\033[0m ')\n",
        "print('Observamos como con solo 18 características podemos mantener toda la información en nuestro modelo')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "xi = np.arange(0, 18, step=1)\n",
        "y = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.ylim(0.0,1.1)\n",
        "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
        "\n",
        "plt.xlabel('Número de Características')\n",
        "plt.xticks(np.arange(0, 20, step=1))\n",
        "plt.ylabel('Porcentaje de varianza acumulada')\n",
        "\n",
        "plt.axhline(y=0.99, color='r', linestyle='-')\n",
        "plt.text(0.5, 0.85, '99% de varianza acumulada', color = 'red', fontsize=16)\n",
        "\n",
        "ax.grid(axis='x')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Jf53bJ37SH4J",
        "outputId": "904792ce-9c28-4434-eea7-3ffb2f2a04ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m FIG 4.2:  Eleccion de componentes de PCA \u001b[0m \n",
            "Observamos como con solo 18 características podemos mantener toda la información en nuestro modelo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "metadata": {
        "id": "1Dfiy6gwTvkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "#Calculamos la matriz de correlacion\n",
        "correlation_mat = X_train.corr()\n",
        "valores = ['nula','debil','moderada','fuerte','total']\n",
        "altura = []\n",
        "\n",
        "#Calculamos el porcentaje de cada clase\n",
        "altura.append(100*len(np.where((correlation_mat == 0.0 ))[0])/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat < 0.5) & (correlation_mat > 0.0)) |  ((correlation_mat > -0.5) & (correlation_mat < 0.0)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat >= 0.5) & (correlation_mat < 0.8)) |  ((correlation_mat <= -0.5) & (correlation_mat >= -0.8)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where(((correlation_mat >= 0.8) & (correlation_mat < 1)) |  ((correlation_mat <= -0.8) & (correlation_mat >= -1)) )[0]))/(X_train.shape[1]*X_train.shape[1]))\n",
        "altura.append((100*len(np.where((correlation_mat == 1 ) | (correlation_mat == -1))[0])/(X_train.shape[1]*X_train.shape[1])))"
      ],
      "metadata": {
        "id": "-g9AJ6aITpqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA Y REDUCCIÓN DE LA CORRELACIÓN**\n",
        "\n",
        "Observamos en la figura 4 como tras aplicar PCA, hemos logrado que todas la variables tengan una correlación débil, conteniendo cada una de ellas información relevante para el modelo. "
      ],
      "metadata": {
        "id": "lpjBCaAzUrFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1mFIG 4.3: Porcentajes de correlación entre variables según el coeficiente pearson TRAS PCA\\033[0m')\n",
        "print('El porcentaje de atributos con relación total es debido a atributos consigo mismos')\n",
        "print('\\033[1mPorcentaje de correlaciones totales : \\033[0m',altura[4])\n",
        "print('\\033[1mPorcentaje de correlaciones de atributos medidas consigo mismo :\\033[0m',100*(1/X_train.shape[1]))\n",
        "print('\\n')\n",
        "plt.title('FIG 4.3: Porcentajes de correlación entre variables según el coeficiente pearson TRAS PCA')\n",
        "plt.xlabel('Tipo de corelación')\n",
        "plt.ylabel('Porcentaje de atributos')\n",
        "plt.bar(valores,altura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "9yvtaue-TqYZ",
        "outputId": "ae35b575-1015-41a7-b609-1748aa829471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mFIG 4.3: Porcentajes de correlación entre variables según el coeficiente pearson TRAS PCA\u001b[0m\n",
            "El porcentaje de atributos con relación total es debido a atributos consigo mismos\n",
            "\u001b[1mPorcentaje de correlaciones totales : \u001b[0m 5.555555555555555\n",
            "\u001b[1mPorcentaje de correlaciones de atributos medidas consigo mismo :\u001b[0m 5.555555555555555\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 303
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>5/6. Interés y justificación de la función/es de pérdida usada / Argumentos a favor de la idoneidad de los modelos seleccionados para la BBDD.</font>\n",
        "\n",
        "**MODELOS CONSIDERADOS**\n",
        "\n",
        "**Modelos Lineales** \n",
        "\n",
        "- El problema consiste en una clasificación de tres clases, por tanto, conjuntos de hipótesis\n",
        "como perceptrón o regresión no parecen interesantes para este problema. Además\n",
        "debemos considerar que el dataset contiene pocos ejemplos y que modelos como el\n",
        "perceptrón multicapa pueden ser penalizados. \n",
        "\n",
        "- Por tanto los modelos escogidos para el\n",
        "problema son:\n",
        "\n",
        "    - **Regresión logística ( modelo lineal )**: este modelo es fácilmente extendible para\n",
        "problemas con múltiples clases, por ejemplo mediante el uso de one-vs-rest\n",
        "transformando el problema en un problema múltiple de clasificación binaria. \n",
        "      \n",
        "      - La función de pérdida por tanto será la entropía cruzada y cambiaremos la función de\n",
        "probabilidad predecida por un función de distribución de probabilidad multinomial.\n",
        "Aporta una medida de cómo de indicado es un predictor para cada una de las clases\n",
        "y obtiene una buena predicción en conjuntos de datos sencillos especialmente\n",
        "cuando son linealmente separables.\n",
        "\n",
        "**Modelos No Lineales**:\n",
        "\n",
        "  - Dado que sólo podíamos elegir entre Perceptrón Multicapa, Random Forest y SVM argumentaremos el por qué de que hayamos elegido SVM y Random Forest sobre Perceptrón Multicapa.\n",
        "\n",
        "\n",
        "  - SVM vs Perceptrón Multicapa: para compararlos debemos entender SVM como un problema de regularización. En este contexto, el análisis comparativo se centra en la función de perdida usada por cada uno de ellos, ya que el término de regularización es común a todos ellos, este es minimizar la norma del vector de pesos.\n",
        "\n",
        "      - Caso Separable: En este caso SVM alcanza la solución óptima en términos de menor dimensión VC, ya que su función de pérdidas busca el hiperplano solución con máxima anchura entre clases. La función de Perceptrón Multicapa solo busca una solución separable.\n",
        "\n",
        "      - Caso No Separable: SVM nos permite a través de la constante C del término de penalización de errores elegir un compromiso entre error y generalización. Para cada valor de C la solución de SVM es óptima ya que maximiza la separabilidad entre clases, por el contrario Perceptrón Multicapca no dispone de dichos mecanismos de compromiso y por tanto sus soluciones  no tienen garantías de optimalidad o de encontrar una solución aceptable.\n",
        "\n",
        "  - Random Forest vs Perceptrón Multicapa: el por qué de la elección de Random Forest sobre Perceptrón Multicapa es que Random Forest nos permite obtener un compromiso sesgo-varianza a diferencia de Perceptron Multicapa que tiende a tener un alto overfit (cosa contra la que puede luchar Random Forest gracias a la poda de nodos) y por tanto una mala generalización, necesitaríamos de una gran cantidad de datos para hacer Perceptrón Multicapa una opción factible, y en vista de que tenemos aproximadamente 2000 datos no parece una cantidad aceptable."
      ],
      "metadata": {
        "id": "Y7tMlqyFWm_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>7. Argumentar sobre la idoneidad de la regularización usada (en su caso)</font>\n",
        "\n",
        "- Al entrenar los pesos sobre un determinado conjunto de entrenamiento, es posible que nos\n",
        "adheramos tanto a la muestra que se produzca sobre entrenamiento en las solución. Dicho\n",
        "sobre entrenamiento se produce mediante un crecimiento de los pesos, lo cual es posible\n",
        "combatir mediante la regularización. Mediante esta técnica, podemos utilizar una clase de\n",
        "funciones grande, y mediante la limitación sobre los pesos tratar de impedir que el modelo\n",
        "saque aprendizaje del ruido estocástico, o que el modelo se centre excesivamente en el\n",
        "ajuste de los datos y como resultado la hipótesis final tenga una complejidad mayor a los\n",
        "propios datos, haciendo que el ruido determinístico aumente.\n",
        "\n",
        "- Existen diversas técnicas para regularizar, todas ellas basadas en añadir restricciones sobre\n",
        "los pesos en nuestro problema de aprendizaje ( usualmente una función positiva de los\n",
        "pesos debe ser acotada por un valor C, aunque pueden ser restricciones más duras como\n",
        "obligar a un cierto número de pesos a ser nulos ). Conocer qué regularización es mejor para\n",
        "un determinado problema no es algo sencillo, pero en líneas generales la regularización ,\n",
        "siempre que no se le de un peso excesivo, suele mejorar los resultados de nuestros\n",
        "modelos.\n",
        "\n",
        "- Nos centraremos en las regularizaciones más típicas, que son aquellas que vienen\n",
        "implementadas en scikit learn: **l1 y l2**. El efecto de ambas regularizaciones , en esencia, es\n",
        "similar. La diferencia entre ambas es debido a su forma de actuar por como están definidas.\n",
        "\n",
        "  - Por un lado **L1** hace tender a los coeficientes hacia valores cercanos a cero, debido a que\n",
        "acota la sumatoria de valores absolutos de los pesos:\n",
        "<font color=blue>$$\\sum_{q=0}^Q |w_q| \\leq C$$</font>\n",
        "\n",
        "  - **L2** por el otro , tiende a reducir los coeficientes de manera uniforme, ya que utiliza la suma\n",
        "de los valores cuadrados:\n",
        "<font color=blue>$$\\sum_{q=0}^Q w_q^2 \\leq C$$</font>\n",
        "\n",
        "  - Podemos considerar por tanto, que normalmente **L1 es útil para la selección de variables**,\n",
        "ya que permite acercarlas más a cero, mientras que **L2 es útil cuando existen\n",
        "características codependientes**. En el análisis de datos no se han encontrado\n",
        "codependencias, por tanto la regularización escogida será L1.\n",
        "\n",
        "- Una vez establecido el tipo de regularización, debemos establecer qué peso se da a dicha\n",
        "regularización. Según hemos explicado, cuanto mayor sea C, más libertad tendrá el modelo\n",
        "para hacer crecer los pesos y por tanto menor valor de regularización tendrá. La elección de\n",
        "C, de forma similar a como pasaba con el learning rate, no es una tarea sencilla ni existe un\n",
        "valor teórico. En la práctica, suelen tomar distintos valores de C y medir los diferentes el\n",
        "rendimiento de los diferentes modelos con dichos valores mediante cross-validation.\n",
        "\n",
        "- Por tanto la mejor opción parece utilizar un GridSearch, el cual es un estimador de\n",
        "parámetros de scikit-learn, que realizará un cross-validation con distintos parámetros para\n",
        "estimar los mejores de ellos.\n",
        "\n"
      ],
      "metadata": {
        "id": "uu-unMfFWsXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red size=5>8. Algoritmo de aprendizaje usado en cada modelo, especificando y justificando los valores de\n",
        "todos los parámetros e hiperparámetros usados.</font>\n",
        "\n",
        "- **Regresion Logística:**\n",
        "\n",
        "  - class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001,\n",
        "C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None,\n",
        "solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False,\n",
        "n_jobs=None, l1_ratio=None):\n",
        "\n",
        "  - **Descripción y justificación de parámetros:**\n",
        "    \n",
        "    - penalty: {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’ - Tipo de regularización escogida, se utilizará l1 como se comentó al utilizar la\n",
        "regularización.\n",
        "\n",
        "    - dual: bool, default=False - Permite la formulación dual en el caso de que utilicemos la regularización l2. Lo\n",
        "dejamos a false, ya que aunque el problema dual puede ser más fácil de solucionar,\n",
        "da problemas con el cálculo de hiperparámetros en gridSearch.\n",
        "\n",
        "    - tol: float, default=1e-4 - Tolerancia del criterio de parada. Se tomará el valor por defecto.\n",
        "\n",
        "    - C: float, default=1.0 - Inversa de la fuerza a aplicar sobre la regularización. Cuanto menor valor tomemos, tendremos una regularización más fuerte. Se calcula mediante GrindSearch.\n",
        "\n",
        "    - fit_interceptbool, default=True - Si se debe añadir un sesgo a la función de decisión. Sabemos que en ocasiones podemos aumentar ligeramente el sesgo y disminuir significativamente la varianza.\n",
        "\n",
        "    - intercept_scaling: float, default=1 - Para modificar el sesgo, añade una característica sintética al resto de instancias,\n",
        "aunque su efecto puede verse decrementado durante la regularización.\n",
        "\n",
        "    - class_weight: dict or ‘balanced’, default=None - Usaremos pesos balanceados como se comentó en el apartado de modelos y\n",
        "funciones de pérdida.\n",
        "\n",
        "    - solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’ - Usaremos lib-linear ya que se presenta una buena elección solo que un poco más lenta que sus competidores. Además permite regularización tanto l1 como l2.\n",
        "\n",
        "    - max_iter: int, default=100 - Máximo número de iteraciones posibles hasta converger: En principio 100 iteraciones parece un número bajo respecto a las implementaciones realizadas en\n",
        "prácticas anteriores. Es preferible tener un número grande de iteraciones y dejar que\n",
        "el algoritmo pare mediante el criterio de parada prematura.\n",
        "\n",
        "    - multi_class {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’ - Para usar liblinear se necesita de ovr.\n",
        "\n",
        "    - verbose: int, default=0 - Expresividad de los algoritmos de resolución. No nos interesa demasiado, la podemos dejar a cero.\n",
        "\n",
        "    - warm_start: bool, default=False - Inicializa mediante los resultados finales de llamadas anteriores a la función.\n",
        "\n",
        "    - n_jobs: int, default=None - Para llevar a cabo una paralelización sobre las clases.\n",
        "\n",
        "    - l1_ratio: float, default=None - Solo usaremos regularización l1 y por tanto este parámetro no es relevante.\n",
        "\n",
        "--------------------------------\n",
        "- **Support Vector Machine (SVC):**\n",
        "\n",
        "  - class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "\n",
        "  - **Descripción y justificación de parámetros**:\n",
        "\n",
        "    - C float, default=1.0 - Inversa de la fuerza a aplicar sobre la regularización. Cuanto menor valor tomemos,\n",
        "tendremos una regularización más fuerte. Se calcula mediante GrindSearch.\n",
        "      \n",
        "    - kernel {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable, default=’rbf’ - Especifica el kernel a utilizar. Esta es una función que permite calcular directamente el\n",
        "producto escalar de los elementos transformados de la matriz en el problema de\n",
        "optimización resuelto, sin tener que aplicar la transformación sobre los datos. Probaremos\n",
        "transformaciones polinómicas sobre los datos y por tanto usaremos el kernel polinomial\n",
        "‘poly’.\n",
        "\n",
        "    - degree int, default=3 - Para el kernel poly, indica el grado del polinomio en la transformación. Cuanto mayor sea el\n",
        "valor del polinomio mayor capacidad tendrá nuestro modelo de ajustar los datos, pero\n",
        "polinomios de grado alto pueden provocar un gran sobreajuste en los datos. Por tanto\n",
        "probaremos dicho kernel con polinomios de hasta grado 3, usando el valor por defecto.\n",
        "\n",
        "    - gamma{‘scale’, ‘auto’} or float, default=’scale’ - Coeficiente del kernel.\n",
        "Usaremos el valor por defecto scale, ya que usa la varianza de los datos siguiendo la\n",
        "fórmula : 1 / (n_features * X.var())\n",
        "\n",
        "   - coef0 float, default=0.0 - Término independiente que se añade al polinomio. Usaremos el valor por defecto (nulo) ya\n",
        "que no tenemos garantías de que algún valor de coeficiente pueda funcionar mejor.\n",
        "\n",
        "    - shrinking bool, default=True - La heurística shrinking, permite acortar el tiempo de entrenamiento cuando el número de\n",
        "iteraciones es grande. Como no buscamos rendimiento en el ajuste del modelo, lo\n",
        "estableceremos a False ya que puede empeorar los resultados.\n",
        "\n",
        "    - probability bool, default=False - Uso de estimaciones probabilísticas. No tenemos garantía de que pueda ser interesante de\n",
        "cara a nuestro problema, por tanto se mantendrá a false.\n",
        "\n",
        "    - tol float, default=1e-3 - Tolerancia de cara al criterio de parada. Mantenemos el valor por defecto.\n",
        "\n",
        "    - cache_size float, default=200 - No afecta al rendimiento, por lo que se mantiene el valor por defecto.\n",
        "\n",
        "    - class_weight dict or ‘balanced’, default=None - Se usará a balanced como se especificó anteriormente en el apartado de modelos y\n",
        "funciones de pérdida.\n",
        "\n",
        "    - verbose bool, default=False - Expresividad de la salida. No afecta al rendimiento.\n",
        "\n",
        "    - max_iter: int, default=-1 - Se mantiene a -1 ya que no existen restricciones de rendimiento, y con este valor se permite\n",
        "al algoritmo converger hasta que encuentre una solución deseada.\n",
        "\n",
        "    - decision_function_shape{‘ovo’, ‘ovr’}, default=’ovr’ - Usaremos One-vs-Rest ya que divide el problema de clasificación multiclase en un\n",
        "problema de clasificación binaria por clase, mientras que One-vs-One utiliza un problema de\n",
        "clasificación binaria por cada pareja de clases.\n",
        "\n",
        "    - break_ties bool, default=False - Mantenemos a false ya que reduce el coste computacional debido a que de esta manera\n",
        "maneja los empates dando un ganador a una de las clases por defecto.\n",
        "\n",
        "    - random_state int, RandomState instance or None, default=None - Controla el número aleatorio en la generación de mezclas, división de batch\n",
        "\n",
        "-------------------------------------------------------\n",
        "\n",
        "- **Random Forest:**\n",
        "  - class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "\n",
        "  - **Descripción y justificación de los parámetros:** Según las indicaciones del profesor, salvo el número de árboles, los demás parámetros usaremos los valores por defecto que se dan en teoría.\n",
        "  \n",
        "    - n_estimators int, default=100 - Representa el número de arboles que generará el algoritmo. Experimentaremos para encontrar el valor correcto.\n",
        "\n",
        "    - criterion{“gini”, “entropy”, “log_loss”}, default=”gini” - determina la función que mide la calidad de la partición. Existen los criterios “gini”, “log_loss” y “entropy”. Este parámetro es específico de los árboles. Usaremos el valor por defecto.\n",
        "\n",
        "    - max_depth int, default=None - Profundidad máxima del arbol. Si se deja a None los nodos son expandidos hasta que todas las hojas sean puras o hasta que contenga menos de min_samples_split muestras. lo dejaremos por defecto\n",
        "\n",
        "    - min_samples_split int or float, default=2 - Número mínimo de muestras requerido para particionar un nodo interno.\n",
        "      - Si vale int, entonces se considera min_samples_split como el mínimo número\n",
        "      - Si vale float, entonces min_samples_split es una fracción y ceil(min_samples_split * n_samples)  es el mínimo número de muestras para cada partición.\n",
        "      - Usaremos el valor por defecto.\n",
        "\n",
        "    - min_samples_leafint or float, default=1 - Número mínimo de muestras requeridas para ser un nodo hoja. Cuanto mayor sea este valor obtendremos una mayor generalización, y por el contrario, cuanto menor sea este valor mayor  será el sobreajuste pero encontrará mayores dificutades de dividir la muestra. Lo dejaremos por defecto\n",
        "\n",
        "    - min_weight_fraction_leaffloat, default=0.0 - Fracción de peso mínimo  de la suma total de pesos (de todas las muestras de entrada) requerido en un nodo hoja. Lo dejaremos por defecto. \n",
        "\n",
        "    - max_features{“sqrt”, “log2”, None}, int or float, default=”sqrt” - Número de características a cosiderar a la hora de buscar la mejor partición. Utilizaremos el valor por defecto, “sqrt” que es el que se usa en general.\n",
        "\n",
        "    - max_leaf_nodesint, default=None - Número máximo de nodos hoja.\n",
        "\n",
        "    - min_impurity_decreasefloat, default=0.0 - Un nodo sera partido si esa partición induce a un decrecimiento de la impureza mayor o igual que este valor.\n",
        "Usaremos el valor por defecto.\n",
        "\n",
        "    - bootstrap bool, default=True - Decide si se permite ajustar árboles a partir de muestras ya muestreadas. Dejaremos el valor por defecto.\n",
        "\n",
        "    - oob_scorebool, default=False - Determina si se usarán las muestras que aún no se han muestreado para estimar la puntuación de generalización. Usaremos el valor por defecto.\n",
        "\n",
        "    - n_jobsint, default=None - Ya que este parámetro afecta a rendimiento es irrelevante.\n",
        "\n",
        "    - random_state int, RandomState instance or None, default=None - Controla tanto la aleatoriedad a la hora de bootstrapping las muestras cuando construimos árboles de decisión, como para la elección de las características a cosiderar cuando buscamos la mejor partición para cada nodo.\n",
        "\n",
        "    - verbose int, default=0 - Controla la expresividad del algoritmo. Lo dejamos a 0 pues es irrelevante.\n",
        "\n",
        "    - warm_start bool, default=False - Reusa la solución de la llamada previa para ajustar y añadir más estimadores. Si está a falso ajusta un completamente nuevo bosque.\n",
        "\n",
        "    - class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None - Ajuste de los pesos a cada clase. Se usará a balanced como se especificó anteriormente en el apartado de modelos y\n",
        "funciones de pérdida.\n",
        "\n",
        "    - ccp_alpha non-negative float, default=0.0 - Configura el valor mínimo de complejidad que determina cuando se realiza una poda de hojas, cuanto mayor sea el valor mayor será el número de nodos podados. Lo dejaremos por defecto.\n",
        "\n",
        "    - max_samples int or float, default=None - Número máximo de muestras. Lo dejaremos por defecto.\n"
      ],
      "metadata": {
        "id": "z8UgmKFeWwL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<font color=red size=5>9. Selección de la mejor hipótesis. Justifique la técnica usada y calcule el error Eout de dicha\n",
        "hipótesis.</font>\n",
        " \n",
        "Una vez establecidos los hiperparámetros, deberemos de escoger un modelo.\n",
        " \n",
        "Según lo acordado, utilizaremos un error de validación medio para la elección del modelo. Para ello lo que haremos será medir los errores de validación mediante 5-cross-validation y realizar una media.\n",
        " \n",
        "$$ E_{cv} = \\frac{1}{5} \\sum_{i=1}^5 E_{val}(g_i^-)$$\n",
        " \n",
        "Al escoger la hipótesis con mejor error de cross-validation, dicho error no podrá considerarse insesgado, pues los hemos utilizado para elegir el modelo ( será un error optimista ). Por tanto una vez tomada la validación para escoger un modelo, entrenaremos con todos los datos de training, y mediremos el error fuera de la muestra a partir del conjunto de test separado previamente, siendo este un error menos.\n",
        " \n",
        " \n",
        "---\n",
        " \n",
        "**class sklearn.model_selection.GridSearchCV**(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
        " \n",
        "- estimator: estimator object\n",
        " \n",
        "estimador para el cual se ajustan los hiperparámetros\n",
        " \n",
        "- param_grid: dict or list of dictionaries\n",
        " \n",
        "Parámetros a probar por GridSearch.\n",
        " \n",
        "- scoring: str, callable, list, tuple or dict, default=None\n",
        " \n",
        "Estrategia para medir el rendimiento de los diferentes cross-validation. Lo mantendremos a no, y usaremos la función de pérdida de cada modelo.\n",
        " \n",
        "- n_jobs: int, default=None\n",
        " \n",
        "No afecta a los resultados del modelo\n",
        " \n",
        "- refit: bool, str, or callable, default=True\n",
        " \n",
        "Lo mantendremos a true para que reajuste el estimador con los mejores hiperparámetros encontrados hasta el momento.\n",
        " \n",
        "- cv: int, cross-validation generator or an iterable, default=None\n",
        " \n",
        "Estrategia de cross-validation a utilizar. Si lo mantenemos a none se utilizará un 5-cross-validation, lo cual es suficiente en nuestro caso para estimar el mejor de los modelos.\n",
        " \n",
        "- verbose: int\n",
        " \n",
        "No afecta a los resultados de la función. Información devuelta por la función.\n",
        " \n",
        "- pre_dispatch: int, or str, default=’2*n_jobs’\n",
        " \n",
        "Controla el número de trabajos que enviados durante la ejecución en paralelo. No afecta al rendimiento.\n",
        " \n",
        "- error_score: ‘raise’ or numeric, default=np.nan\n",
        " \n",
        "Valor que se asigna al score en el caso de que ocurra un error, por ejemplo, que dos parámetros no sean compatibles.\n",
        " \n",
        "- return_train_score: bool, default=False\n",
        " \n",
        "Devuelve en los scores el valor de training, aunque el que nos interesa es el error de cross-validation.\n",
        " \n",
        "---\n",
        " \n",
        "Compararemos nuestros modelos mediante el uso de cross-validation, donde mediremos una vez escogemos los mejores hiperparámetros de cada modelo, el mejor rendimiento de cada uno de ellos según las diferentes métricas de error.\n",
        " \n"
      ],
      "metadata": {
        "id": "7Uu51pa1b2kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**MÉTRICAS DE ERROR**\n",
        "\n",
        "El desbalance de clases supone un problema a la hora de medir el buen funcionamiento de un modelo. Por ejemplo, si nos fijamos en el accuracy en un modelo que nos diga la clase más frecuente ( no podemos considerar que dicho modelo haya realizado un aprendizaje ) podemos obtener porcentajes altos , en nuestro caso cercanos al 80%. Según la naturaleza del proyecto podemos estipular cuál es la prioridad de cada uno de los objetivos a alcanzar. En este caso el coste de un fallo puede tener consecuencias más o menos significativas dependiendo de este. De esta forma establecemos los siguientes objetivos:\n",
        "\n",
        "1. Detectar los fetos que contienen patologías: debido al riesgo que pueden presentar estas para el feto, es lo más importante a detectar para que estas puedan ser tratadas a tiempo de cara a la salud del mismo.\n",
        "\n",
        "2. Detectar los fetos sospechosos: si algún feto puede ser sospechoso de enfermedad, es interesante detectar esto a tiempo para la realización de más pruebas en un futuro que puedan detectar posibles problemas en el mismo.\n",
        "\n",
        "  - Para ellos mediremos la **sensitivity:** porcentaje de elementos con etiqueta \"si\" que fueron bien clasificados. Implementada en scikit-learn como recall.\n",
        "$$ \\frac{TruePositive}{True Positive + FalseNegative } $$\n",
        " \n",
        "3. También será interesante un buen porcentaje de accuracy en el modelo. Aunque puede considerarse un objetivo secundario, también es importante que por ejemplo a un feto normal o sospechoso no se le detecte directamente como una patología, ya que aunque no tiene consecuencias tan negativas como el caso contrario, no es deseable que nuestro modelo cometa este tipo de errores. Puede ser usado como criterio de desempate. Para ello podemos usar\n",
        " \n",
        "  - **Accuracy:** porcentaje de elementos bien clasificados. \n",
        " \n",
        "$$ \\frac{TrueNegative + TrueNegative}{ TrueNegative + TruePositive + FalseNegative + FalsePositive} $$\n",
        "\n",
        "  - **balanced accuracy**: realiza una estimación del recall medio en cada clase\n",
        " \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UkUP20yan_Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "iso = IsolationForest(contamination=0.01)\n",
        "yhat = iso.fit_predict(X_train)\n",
        "\n",
        "#valores con los que nos quedamos\n",
        "mask = yhat != -1\n",
        "print(mask)\n",
        "print(\"\\033[1mTamaño del dataset antes de eliminar outliers\\033[0m\")\n",
        "print(X_train.shape)\n",
        "#X_train = X_train.drop(df.index(mask),axis=0)\n",
        "X_train, y_train = X_train.loc[mask, :], y_train.loc[mask]\n",
        "#y_train = y_train.drop(mask[0][:],axis=0)\n",
        "print(\"\\033[1mTamaño del dataset depués de eliminar outliers\\033[0m\")\n",
        "print(X_train.shape)\n",
        "'''"
      ],
      "metadata": {
        "id": "Ji7Uf9w01Gw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ab205198-5387-4036-b123-2e814171175a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.ensemble import IsolationForest\\n\\niso = IsolationForest(contamination=0.01)\\nyhat = iso.fit_predict(X_train)\\n\\n#valores con los que nos quedamos\\nmask = yhat != -1\\nprint(mask)\\nprint(\"\\x1b[1mTamaño del dataset antes de eliminar outliers\\x1b[0m\")\\nprint(X_train.shape)\\n#X_train = X_train.drop(df.index(mask),axis=0)\\nX_train, y_train = X_train.loc[mask, :], y_train.loc[mask]\\n#y_train = y_train.drop(mask[0][:],axis=0)\\nprint(\"\\x1b[1mTamaño del dataset depués de eliminar outliers\\x1b[0m\")\\nprint(X_train.shape)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n"
      ],
      "metadata": {
        "id": "VFQnt7_165wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion que mide la media en los valores de una lista\n",
        "#https://www.geeksforgeeks.org/find-average-list-python/\n",
        "def average(lst):\n",
        "    return sum(lst) / len(lst)"
      ],
      "metadata": {
        "id": "ciYoioR8XNcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "cross_balanced = LogisticRegression(random_state=0,max_iter=40000,class_weight='balanced',penalty='l1',solver='liblinear')\n",
        " \n",
        "parameters = {\n",
        "   'C':[0.1,0.4,0.6,0.75,0.8,0.9,0.95,1,1.2,1.4,1.7,2]\n",
        "}\n",
        "#Calculamos el estimador según el mejor de los hiperparámetros\n",
        "clf = GridSearchCV(cross_balanced, parameters,refit='recall')\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "print(\"\\033[1m HIPERPARÁMETROS ESCOGIDOS RIDGE\\033[0m \\n\")\n",
        "print(clf.best_params_)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D7S9W6aY4Yyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb73fdbd-e052-48f4-b641-69ae97271cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m HIPERPARÁMETROS ESCOGIDOS RIDGE\u001b[0m \n",
            "\n",
            "{'C': 0.4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "parametros1 = clf.cv_results_\n",
        "scoring=['recall','balanced_accuracy','precision','accuracy','f1']\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "LR_accu = []\n",
        "LR_balanced = []\n",
        "LR_recall_suspect = []\n",
        "LR_recall_pathologic = []\n",
        "  \n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    x_train_fold, x_test_fold = X_train[train_index],  X_train[test_index]\n",
        "    y_train_fold, y_test_fold =  y_train[train_index],  y_train[test_index]\n",
        "    clf.fit(x_train_fold, y_train_fold)\n",
        "    y_pred = clf.predict(x_test_fold)\n",
        "    LR_balanced.append(balanced_accuracy_score(y_test_fold, y_pred))\n",
        "    LR_recall_suspect.append(recall_score(y_test_fold, y_pred,labels=[2.0], average='micro'))\n",
        "    LR_recall_pathologic.append(recall_score(y_test_fold, y_pred,labels=[3.0], average='micro'))\n",
        "    LR_accu.append(accuracy_score(y_test_fold, y_pred))\n",
        "    \n",
        "   "
      ],
      "metadata": {
        "id": "fBa6kD20_aVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\033[1m--REGRESIÓN LOGISTICA--\\033[0m\")\n",
        "\n",
        "print(\"\\033[1mBALANCED ACCURACY\\033[0m\")\n",
        "print( average(LR_balanced) )\n",
        "print(\"\\033[1mSUSPECT RECALL\\033[0m\")\n",
        "print( average(LR_recall_suspect) )\n",
        "print(\"\\033[1mPATHOLOGIC RECALL\\033[0m\")\n",
        "print( average(LR_recall_pathologic))\n",
        "print(\"\\033[1mACCURACY\\033[0m\")\n",
        "print( average(LR_accu))\n"
      ],
      "metadata": {
        "id": "Sy4u9ZWv5Ol2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49031a53-ab36-4012-b494-6112bbe8540f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m--REGRESIÓN LOGISTICA--\u001b[0m\n",
            "\u001b[1mBALANCED ACCURACY\u001b[0m\n",
            "0.8144256003705193\n",
            "\u001b[1mSUSPECT RECALL\u001b[0m\n",
            "0.7581560283687944\n",
            "\u001b[1mPATHOLOGIC RECALL\u001b[0m\n",
            "0.7660098522167488\n",
            "\u001b[1mACCURACY\u001b[0m\n",
            "0.8841176470588235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rForest = RandomForestClassifier(random_state=0,class_weight='balanced')\n",
        "\n",
        "parameters = {\n",
        "   'n_estimators':[50,75,100,125,150,175,200]\n",
        "}\n",
        "\n",
        "rForest = GridSearchCV(rForest, parameters)\n",
        "rForest.fit(X_train,y_train)\n",
        "\n",
        "print(\"\\033[1m HIPERPARÁMETROS ESCOGIDOS RANDOMFOREST\\033[0m \\n\")\n",
        "print(rForest.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "id": "aJqu2vqCHIRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6271b9-1208-45eb-9705-c213bd61fa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m HIPERPARÁMETROS ESCOGIDOS RANDOMFOREST\u001b[0m \n",
            "\n",
            "{'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rF_accu = []\n",
        "rF_balanced = []\n",
        "rF_recall_suspect = []\n",
        "rF_recall_pathologic = []\n",
        "\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    x_train_fold, x_test_fold = X_train[train_index],  X_train[test_index]\n",
        "    y_train_fold, y_test_fold =  y_train[train_index],  y_train[test_index]\n",
        "    rForest.fit(x_train_fold, y_train_fold)\n",
        "    y_pred = rForest.predict(x_test_fold)\n",
        "    rF_balanced.append(balanced_accuracy_score(y_test_fold, y_pred))\n",
        "    rF_recall_suspect.append(recall_score(y_test_fold, y_pred,labels=[2.0], average='micro'))\n",
        "    rF_recall_pathologic.append(recall_score(y_test_fold, y_pred,labels=[3.0], average='micro'))\n",
        "    rF_accu.append(accuracy_score(y_test_fold, y_pred))\n",
        "    "
      ],
      "metadata": {
        "id": "Kn7HBIHSHQ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\033[1m--RANDOM FOREST--\\033[0m\")\n",
        "\n",
        "print(\"\\033[1mBALANCED ACCURACY\\033[0m\")\n",
        "print( average(rF_balanced) )\n",
        "print(\"\\033[1mSUSPECT RECALL\\033[0m\")\n",
        "print( average(rF_recall_suspect) )\n",
        "print(\"\\033[1mPATHOLOGIC RECALL\\033[0m\")\n",
        "print( average(rF_recall_pathologic))\n",
        "print(\"\\033[1mACCURACY\\033[0m\")\n",
        "print( average(rF_accu))"
      ],
      "metadata": {
        "id": "iz9M2XqvHSIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8478db6c-722c-40a7-ac40-31225837676f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m--RANDOM FOREST--\u001b[0m\n",
            "\u001b[1mBALANCED ACCURACY\u001b[0m\n",
            "0.7653729427331637\n",
            "\u001b[1mSUSPECT RECALL\u001b[0m\n",
            "0.5418439716312057\n",
            "\u001b[1mPATHOLOGIC RECALL\u001b[0m\n",
            "0.7724137931034483\n",
            "\u001b[1mACCURACY\u001b[0m\n",
            "0.9035294117647059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(gamma='auto',class_weight='balanced',kernel='poly')\n",
        "parameters = {\n",
        "     'C':[0.1,0.4,0.6,0.75,0.8,0.9,0.95,1,1.2,1.4,1.7,2],\n",
        "}\n",
        "svc = GridSearchCV(svc, parameters)\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "print(\"\\033[1m HIPERPARÁMETROS ESCOGIDOS SVC\\033[0m \\n\")\n",
        "print(svc.best_params_)"
      ],
      "metadata": {
        "id": "bCYj0P7sNNNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179cfede-9481-4bc7-e813-c9647231d78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m HIPERPARÁMETROS ESCOGIDOS SVC\u001b[0m \n",
            "\n",
            "{'C': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_accu = []\n",
        "svm_balanced = []\n",
        "svm_recall_suspect = []\n",
        "svm_recall_pathologic = []\n",
        "\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    x_train_fold, x_test_fold = X_train[train_index],  X_train[test_index]\n",
        "    y_train_fold, y_test_fold =  y_train[train_index],  y_train[test_index]\n",
        "    svc.fit(x_train_fold, y_train_fold)\n",
        "    y_pred = svc.predict(x_test_fold)\n",
        "    svm_balanced.append(balanced_accuracy_score(y_test_fold, y_pred))\n",
        "    svm_recall_suspect.append(recall_score(y_test_fold, y_pred,labels=[2.0], average='micro'))\n",
        "    svm_recall_pathologic.append(recall_score(y_test_fold, y_pred,labels=[3.0], average='micro'))\n",
        "    svm_accu.append(accuracy_score(y_test_fold, y_pred))"
      ],
      "metadata": {
        "id": "oJQjpc7iOYtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\033[1m--SVM--\\033[0m\")\n",
        "\n",
        "print(\"\\033[1mBALANCED ACCURACY\\033[0m\")\n",
        "print( average(svm_balanced) )\n",
        "print(\"\\033[1mSUSPECT RECALL\\033[0m\")\n",
        "print( average(svm_recall_suspect) )\n",
        "print(\"\\033[1mPATHOLOGIC RECALL\\033[0m\")\n",
        "print( average(svm_recall_pathologic))\n",
        "print(\"\\033[1mACCURACY\\033[0m\")\n",
        "print( average(svm_accu))"
      ],
      "metadata": {
        "id": "Kv12f2-dOeg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a1be63-1e75-4fe3-853f-ba350f3e1149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m--SVM--\u001b[0m\n",
            "\u001b[1mBALANCED ACCURACY\u001b[0m\n",
            "0.8673364435898179\n",
            "\u001b[1mSUSPECT RECALL\u001b[0m\n",
            "0.864095744680851\n",
            "\u001b[1mPATHOLOGIC RECALL\u001b[0m\n",
            "0.8362068965517242\n",
            "\u001b[1mACCURACY\u001b[0m\n",
            "0.8911764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#________________________TABLA SOBRE RESULTADOS________________________\n",
        "modelos = ['LR' ,'RF' ,'SVM']\n",
        "BA = [average(LR_balanced),average(rF_balanced),average(svm_balanced)]\n",
        "SR = [average(LR_recall_suspect),average(rF_recall_suspect),average(svm_recall_suspect)]\n",
        "PR = [average(LR_recall_pathologic),average(rF_recall_pathologic),average(svm_recall_pathologic)]\n",
        "AC = [average(LR_accu),average(rF_accu),average(svm_accu)]\n",
        "\n",
        "info = {'\\033[1mMODELO\\033[0m': modelos[:],\n",
        "        '\\033[1mBALANCED ACCURACY\\033[0m': BA[:],\n",
        "        '\\033[1mSUSPECT RECALL\\033[0m': SR[:],\n",
        "        '\\033[1mPATHOLOGIC RECALL\\033[0m': PR[:],\n",
        "        '\\033[1mACCURACY\\033[0m': AC[:]}\n",
        "print(\"\\033[1m\"+'\\nTabla 9.1 RESULTADOS  MEDIOS SOBRE CROSS-VALIDATION'+\"\\033[0m\")\n",
        "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgyqmU0YZrUP",
        "outputId": "17431cee-b5d0-49a9-9995-5e74606baca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "Tabla 9.1 RESULTADOS  MEDIOS SOBRE CROSS-VALIDATION\u001b[0m\n",
            "╒══════════╤═════════════════════╤══════════════════╤═════════════════════╤════════════╕\n",
            "│ \u001b[1mMODELO\u001b[0m   │   \u001b[1mBALANCED ACCURACY\u001b[0m │   \u001b[1mSUSPECT RECALL\u001b[0m │   \u001b[1mPATHOLOGIC RECALL\u001b[0m │   \u001b[1mACCURACY\u001b[0m │\n",
            "╞══════════╪═════════════════════╪══════════════════╪═════════════════════╪════════════╡\n",
            "│ LR       │            0.814426 │         0.758156 │            0.76601  │   0.884118 │\n",
            "├──────────┼─────────────────────┼──────────────────┼─────────────────────┼────────────┤\n",
            "│ RF       │            0.765373 │         0.541844 │            0.772414 │   0.903529 │\n",
            "├──────────┼─────────────────────┼──────────────────┼─────────────────────┼────────────┤\n",
            "│ SVM      │            0.867336 │         0.864096 │            0.836207 │   0.891176 │\n",
            "╘══════════╧═════════════════════╧══════════════════╧═════════════════════╧════════════╛\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELO ESCOGIDO**\n",
        "\n",
        "Debido a que es el que presenta mayor capacidad en media tanto para detectar fetos sospechosos como patológicos, se tomara SVM como el mejor de los modelos. Para estimar el error fuera de la muestra previamente entrenaremos el modelo con todos los datos de entrenamiento y utilizaremos el error de test para medir los resultados del modelo."
      ],
      "metadata": {
        "id": "PynHyjzRp3mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m\\nEstimación del error de test\\033[0m', 1 - svc.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b4d2QXarJN6",
        "outputId": "bb355e7e-e6c9-4c08-955c-418b050cb3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "Estimación del error de test\u001b[0m 0.11267605633802813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$E_{out}(h) \\leq  0,15497 $$\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "8yIHr6yeryED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "<font color=red size=5>10. Valoración de los resultados ( gráficas, métricas de error, análisis de residuos, etc )</font>"
      ],
      "metadata": {
        "id": "wKJSnZTJsUta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para medir si nuestro modelo ha aprendido realmente, podemos obtener un modelo como baseline y medir los resultados respecto de este. \n",
        "\n",
        "De cara a la comparativa usaremos un estimador que no utiliza parámetros para ajustar un modelo, siempre devolverá la etiqueta más frecuente y tendrá cierta precisión gracias a la descompensación dentro de las clases:\n",
        "**class sklearn.dummy.DummyClassifier**(*, strategy='prior', random_state=None, constant=None):\n",
        "- strategy{“most_frequent”, “prior”, “stratified”, “uniform”, “constant”}, default=”prior”\n",
        "Usaremos most_frequent que es la estretégia que queremos implementar\n",
        "- random_state: int, RandomState instance or None, default=None\n",
        "Aporta aleatoriedad al usar otras estrategias. No nos interesa.\n",
        "- constant: int or str or array-like of shape (n_outputs,), default=None\n",
        "Para la estrategia \"constante\".\n",
        "---\n",
        "Referencia:\n",
        "1. DummyClassifier = https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n",
        " "
      ],
      "metadata": {
        "id": "SDrynjTecU9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "dummy_accu = []\n",
        "dummy_balanced = []\n",
        "dummy_recall_suspect = []\n",
        "dummy_recall_pathologic = []\n",
        "\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    x_train_fold, x_test_fold = X_train[train_index],  X_train[test_index]\n",
        "    y_train_fold, y_test_fold =  y_train[train_index],  y_train[test_index]\n",
        "    dummy_clf.fit(x_train_fold, y_train_fold)\n",
        "    y_pred = dummy_clf.predict(x_test_fold)\n",
        "    dummy_balanced.append(balanced_accuracy_score(y_test_fold, y_pred))\n",
        "    dummy_recall_suspect.append(recall_score(y_test_fold, y_pred,labels=[2.0], average='micro'))\n",
        "    dummy_recall_pathologic.append(recall_score(y_test_fold, y_pred,labels=[3.0], average='micro'))\n",
        "    dummy_accu.append(accuracy_score(y_test_fold, y_pred))\n"
      ],
      "metadata": {
        "id": "ZcEDNPNzW4vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se observa en la figura 10.1, los resultados de SVM mejoran considerablemente en todas la métricas respecto del baseline, esto nos indica que el modelo realmente a obtenido un aprendizaje."
      ],
      "metadata": {
        "id": "-UBzSGLOvy0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#________________________TABLA SOBRE RESULTADOS________________________\n",
        "modelos = ['DUMMY' ,'SVM']\n",
        "BA = [average(dummy_balanced),average(svm_balanced)]\n",
        "SR = [average(dummy_recall_suspect),average(svm_recall_suspect)]\n",
        "PR = [average(dummy_recall_pathologic),average(svm_recall_pathologic)]\n",
        "AC = [average(dummy_accu),average(svm_accu)]\n",
        "\n",
        "info = {'\\033[1mMODELO\\033[0m': modelos[:],\n",
        "        '\\033[1mBALANCED ACCURACY\\033[0m': BA[:],\n",
        "        '\\033[1mSUSPECT RECALL\\033[0m': SR[:],\n",
        "        '\\033[1mPATHOLOGIC RECALL\\033[0m': PR[:],\n",
        "        '\\033[1mACCURACY\\033[0m': AC[:]}\n",
        "print(\"\\033[1m\"+'\\nTabla 10.1 COMPARACIÓN CON UN MODELO DUMMY'+\"\\033[0m\")\n",
        "print(tabulate(info, headers='keys', tablefmt='fancy_grid'))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cd1SQZxW94E",
        "outputId": "1220fa07-0fbf-4988-e72f-b6e707713b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "Tabla 10.1 COMPARACIÓN CON UN MODELO DUMMY\u001b[0m\n",
            "╒══════════╤═════════════════════╤══════════════════╤═════════════════════╤════════════╕\n",
            "│ \u001b[1mMODELO\u001b[0m   │   \u001b[1mBALANCED ACCURACY\u001b[0m │   \u001b[1mSUSPECT RECALL\u001b[0m │   \u001b[1mPATHOLOGIC RECALL\u001b[0m │   \u001b[1mACCURACY\u001b[0m │\n",
            "╞══════════╪═════════════════════╪══════════════════╪═════════════════════╪════════════╡\n",
            "│ DUMMY    │            0.333333 │         0        │            0        │   0.778235 │\n",
            "├──────────┼─────────────────────┼──────────────────┼─────────────────────┼────────────┤\n",
            "│ SVM      │            0.867336 │         0.864096 │            0.836207 │   0.891176 │\n",
            "╘══════════╧═════════════════════╧══════════════════╧═════════════════════╧════════════╛\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se observa en la figura 10.2,en términos generales, se puede observar con las curvas de aprendizaje como el modelos obtiene mejor generalización conforme aumentamos el número de puntos con los que entrenar el modelo"
      ],
      "metadata": {
        "id": "TvCiFrrax0RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_curva, X_test_curva, y_train_curva, y_test_curva = train_test_split(X_train, y_train, test_size = 0.1, random_state = 46752,stratify=y_train)\n",
        "\n",
        "ErroresIn = []\n",
        "ErroresTest = []\n",
        "point = []\n",
        "\n",
        "for i in range(50,X_train_curva.shape[0],50):\n",
        "  point.append(i)\n",
        "  conjuntoX = X_train_curva[:i]\n",
        "  etiquetasY = y_train_curva[:i]\n",
        "  svc.fit(conjuntoX,etiquetasY)\n",
        "  ErroresIn.append(1-svc.score(conjuntoX,etiquetasY))\n",
        "  ErroresTest.append(1-svc.score(X_test_curva,y_test_curva))"
      ],
      "metadata": {
        "id": "qsZcnA-wwfvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1mFIG 10.2: CURVAS DE APRENDIZAJE\\033[0m')\n",
        "\n",
        "plt.plot(point,ErroresTest,c='red',label='E_test')\n",
        "plt.plot(point,ErroresIn,c='blue',label = 'E_in')\n",
        "plt.legend()\n",
        "plt.xlabel('Número de elementos N')\n",
        "plt.ylabel('Error')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "3ixNKtCWwpzx",
        "outputId": "4a0d56a4-9fe5-4ab0-885a-f2fd3c5c943b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mFIG 10.2: CURVAS DE APRENDIZAJE\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {},
          "execution_count": 322
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<font color=red size=5>11. Argumente que se ha obtenido la mejor de las posibles soluciones para la muestra dada.\n",
        "Argumentar en términos de los errores de ajuste y generalización.</font>"
      ],
      "metadata": {
        "id": "BWSKvb11VbaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede considerar que la solución es la mejor de las posibles gracias a que su función de perdida busca el hiperplano con máximo anchura entre clases. Podemos ver como en la figura 11.1 como a partir de ciertas iteraciones, el error queda constantes ya que el propio modelo evita el sobreajuste por naturaleza."
      ],
      "metadata": {
        "id": "MU0SvUwdy4ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mejorScore = 100.0\n",
        "ErroresIn = []\n",
        "ErroresTest = []\n",
        "point = []\n",
        "\n",
        "for i in np.arange(10, 10000, 200):\n",
        "    svm = SVC(max_iter=i,gamma='auto',class_weight='balanced',kernel='poly') \n",
        "    svm.fit(X_train, y_train)\n",
        "    point.append(i)\n",
        "    score = 1 - svm.score(X_test,y_test)\n",
        "    ErroresIn.append(1 - svm.score(X_train,y_train))\n",
        "    ErroresTest.append(score)\n",
        "    if score < mejorScore:\n",
        "      mejorModelo = svm\n",
        "      mejorScore = score\n",
        "    \n"
      ],
      "metadata": {
        "id": "gvQ9XQWmz91C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1mFIG 11.1: EARLY-STOPPING\\033[0m')\n",
        "\n",
        "plt.plot(point,ErroresTest,c='red',label='E_test')\n",
        "plt.plot(point,ErroresIn,c='blue',label = 'E_in')\n",
        "plt.legend()\n",
        "plt.xlabel('Número de elementos N')\n",
        "plt.ylabel('Error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "PvTSvQas1f7y",
        "outputId": "1e352c08-e658-43d1-e73a-d95d324f36da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mFIG 11.1: EARLY-STOPPING\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {},
          "execution_count": 326
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}